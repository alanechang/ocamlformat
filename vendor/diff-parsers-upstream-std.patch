--- parser-upstream/ast_helper.ml
+++ parser-standard/ast_helper.ml
@@@@
             Ptyp_constr(longident, List.map loop lst)
         | Ptyp_object (lst, o) ->
             Ptyp_object (List.map loop_object_field lst, o)
         | Ptyp_class (longident, lst) ->
             Ptyp_class (longident, List.map loop lst)
+        (* A Ptyp_alias might be a layout annotation (that is, it might have
+           attributes which mean it should be interpreted as a
+           [Jane_syntax.Layouts.Ltyp_alias]), but the code here still has the
+           correct behavior. *)
         | Ptyp_alias(core_type, string) ->
             check_variable var_names t.ptyp_loc string;
             Ptyp_alias(loop core_type, string)
         | Ptyp_variant(row_field_list, flag, lbl_lst_option) ->
             Ptyp_variant(List.map loop_row_field row_field_list,
@@@@
   let open_ ?loc ?attrs a b = mk ?loc ?attrs (Pexp_open (a, b))
   let letop ?loc ?attrs let_ ands body =
     mk ?loc ?attrs (Pexp_letop {let_; ands; body})
   let extension ?loc ?attrs a = mk ?loc ?attrs (Pexp_extension a)
   let unreachable ?loc ?attrs () = mk ?loc ?attrs Pexp_unreachable
+  let hole  ?loc ?attrs () = mk ?loc ?attrs Pexp_hole
 
   let case lhs ?guard rhs =
     {
      pc_lhs = lhs;
      pc_guard = guard;
@@@@
     mk ?loc ?attrs (Pmod_functor (arg, body))
   let apply ?loc ?attrs m1 m2 = mk ?loc ?attrs (Pmod_apply (m1, m2))
   let constraint_ ?loc ?attrs m mty = mk ?loc ?attrs (Pmod_constraint (m, mty))
   let unpack ?loc ?attrs e = mk ?loc ?attrs (Pmod_unpack e)
   let extension ?loc ?attrs a = mk ?loc ?attrs (Pmod_extension a)
+  let hole ?loc ?attrs () = mk ?loc ?attrs Pmod_hole
 end
 
 module Sig = struct
   let mk ?(loc = !default_loc) d = {psig_desc = d; psig_loc = loc}
 
@@@@
 
 module Type = struct
   let mk ?(loc = !default_loc) ?(attrs = [])
         ?(docs = empty_docs) ?(text = [])
       ?(params = [])
+      ?layout
       ?(cstrs = [])
       ?(kind = Ptype_abstract)
       ?(priv = Public)
       ?manifest
       name =
+    let layout_attrs = Option.to_list layout in
     {
      ptype_name = name;
      ptype_params = params;
      ptype_cstrs = cstrs;
      ptype_kind = kind;
      ptype_private = priv;
      ptype_manifest = manifest;
      ptype_attributes =
-       add_text_attrs text (add_docs_attrs docs attrs);
+      layout_attrs @ add_text_attrs text (add_docs_attrs docs attrs);
      ptype_loc = loc;
     }
 
   let constructor ?(loc = !default_loc) ?(attrs = []) ?(info = empty_info)
         ?(vars = []) ?(args = Pcstr_tuple []) ?res name =
--- parser-upstream/ast_helper.mli
+++ parser-standard/ast_helper.mli
@@@@
     val varify_constructors: str list -> core_type -> core_type
     (** [varify_constructors newtypes te] is type expression [te], of which
         any of nullary type constructor [tc] is replaced by type variable of
         the same name, if [tc]'s name appears in [newtypes].
         Raise [Syntaxerr.Variable_in_scope] if any type variable inside [te]
-        appears in [newtypes].
+        appears in [newtypes]. Used to translate [type a. a -> a] to
+        ['a. 'a -> 'a] during parsing.
         @since 4.05
      *)
   end
 
 (** Patterns *)
@@@@
     val extension: ?loc:loc -> ?attrs:attrs -> extension -> expression
     val unreachable: ?loc:loc -> ?attrs:attrs -> unit -> expression
 
     val case: pattern -> ?guard:expression -> expression -> case
     val binding_op: str -> pattern -> expression -> loc -> binding_op
+    val hole: ?loc:loc -> ?attrs:attrs -> unit -> expression
   end
 
 (** Value declarations *)
 module Val:
   sig
@@@@
 (** Type declarations *)
 module Type:
   sig
     val mk: ?loc:loc -> ?attrs:attrs -> ?docs:docs -> ?text:text ->
       ?params:(core_type * (variance * injectivity)) list ->
+      ?layout:attribute ->
       ?cstrs:(core_type * core_type * loc) list ->
       ?kind:type_kind -> ?priv:private_flag -> ?manifest:core_type -> str ->
       type_declaration
 
     val constructor: ?loc:loc -> ?attrs:attrs -> ?info:info ->
@@@@
       module_expr
     val constraint_: ?loc:loc -> ?attrs:attrs -> module_expr -> module_type ->
       module_expr
     val unpack: ?loc:loc -> ?attrs:attrs -> expression -> module_expr
     val extension: ?loc:loc -> ?attrs:attrs -> extension -> module_expr
+    val hole: ?loc:loc -> ?attrs:attrs -> unit -> module_expr
   end
 
 (** Signature items *)
 module Sig:
   sig
--- parser-upstream/ast_mapper.ml
+++ parser-standard/ast_mapper.ml
@@@@
   type_exception: mapper -> type_exception -> type_exception;
   type_kind: mapper -> type_kind -> type_kind;
   value_binding: mapper -> value_binding -> value_binding;
   value_description: mapper -> value_description -> value_description;
   with_constraint: mapper -> with_constraint -> with_constraint;
+  directive_argument: mapper -> directive_argument -> directive_argument;
+  toplevel_directive: mapper -> toplevel_directive -> toplevel_directive;
+  toplevel_phrase: mapper -> toplevel_phrase -> toplevel_phrase;
 }
 
 let map_fst f (x, y) = (f x, y)
 let map_snd f (x, y) = (x, f y)
 let map_tuple f1 f2 (x, y) = (f1 x, f2 y)
@@@@
     | Pmod_constraint (m, mty) ->
         constraint_ ~loc ~attrs (sub.module_expr sub m)
                     (sub.module_type sub mty)
     | Pmod_unpack e -> unpack ~loc ~attrs (sub.expr sub e)
     | Pmod_extension x -> extension ~loc ~attrs (sub.extension sub x)
+    | Pmod_hole -> hole ~loc ~attrs ()
 
   let map_structure_item sub {pstr_loc = loc; pstr_desc = desc} =
     let open Str in
     let loc = sub.location sub loc in
     match desc with
@@@@
     | Pexp_letop {let_; ands; body} ->
         letop ~loc ~attrs (sub.binding_op sub let_)
           (List.map (sub.binding_op sub) ands) (sub.expr sub body)
     | Pexp_extension x -> extension ~loc ~attrs (sub.extension sub x)
     | Pexp_unreachable -> unreachable ~loc ~attrs ()
+    | Pexp_hole -> hole ~loc ~attrs ()
 
   let map_binding_op sub {pbop_op; pbop_pat; pbop_exp; pbop_loc} =
     let open Exp in
     let op = map_loc sub pbop_op in
     let pat = sub.pat sub pbop_pat in
@@@@
          | PStr x -> PStr (this.structure this x)
          | PSig x -> PSig (this.signature this x)
          | PTyp x -> PTyp (this.typ this x)
          | PPat (x, g) -> PPat (this.pat this x, map_opt (this.expr this) g)
       );
+
+    directive_argument =
+      (fun this a ->
+         { pdira_desc= a.pdira_desc
+         ; pdira_loc= this.location this a.pdira_loc} );
+
+    toplevel_directive =
+      (fun this d ->
+         { pdir_name= map_loc this d.pdir_name
+         ; pdir_arg= map_opt (this.directive_argument this) d.pdir_arg
+         ; pdir_loc= this.location this d.pdir_loc } );
+
+    toplevel_phrase =
+      (fun this -> function
+         | Ptop_def s -> Ptop_def (this.structure this s)
+         | Ptop_dir d -> Ptop_dir (this.toplevel_directive this d) );
   }
 
 let extension_of_error {kind; main; sub} =
   if kind <> Location.Report_error then
     raise (Invalid_argument "extension_of_error: expected kind Report_error");
@@@@
       | "tool_name" ->
           tool_name_ref := get_string payload
       | "include_dirs" ->
           Clflags.include_dirs := get_list get_string payload
       | "load_path" ->
-          (* Duplicates Compmisc.auto_include, since we can't reference Compmisc
-             from this module. *)
-          let auto_include find_in_dir fn =
-            if !Clflags.no_std_include then
-              raise Not_found
-            else
-              let alert = Location.auto_include_alert in
-              Load_path.auto_include_otherlibs alert find_in_dir fn
-          in
-          Load_path.init ~auto_include (get_list get_string payload)
+          ()
       | "open_modules" ->
           Clflags.open_modules := get_list get_string payload
       | "for_package" ->
           Clflags.for_package := get_option get_string payload
       | "debug" ->
--- parser-upstream/ast_mapper.mli
+++ parser-standard/ast_mapper.mli
@@@@
   type_exception: mapper -> type_exception -> type_exception;
   type_kind: mapper -> type_kind -> type_kind;
   value_binding: mapper -> value_binding -> value_binding;
   value_description: mapper -> value_description -> value_description;
   with_constraint: mapper -> with_constraint -> with_constraint;
+  directive_argument: mapper -> directive_argument -> directive_argument;
+  toplevel_directive: mapper -> toplevel_directive -> toplevel_directive;
+  toplevel_phrase: mapper -> toplevel_phrase -> toplevel_phrase;
 }
 (** A mapper record implements one "method" per syntactic category,
     using an open recursion style: each method takes as its first
     argument the mapper to be applied to children in the syntax
     tree. *)
--- parser-upstream/asttypes.mli
+++ parser-standard/asttypes.mli
@@@@
 
 type override_flag = Override | Fresh
 
 type closed_flag = Closed | Open
 
-type label = string
-
-type arg_label =
-    Nolabel
-  | Labelled of string (** [label:T -> ...] *)
-  | Optional of string (** [?label:T -> ...] *)
+type global_flag =
+  | Global
+  | Nothing
 
 type 'a loc = 'a Location.loc = {
   txt : 'a;
   loc : Location.t;
 }
 
+(* constant layouts are parsed as layout annotations, and also used
+   in the type checker as already-inferred (i.e. non-variable) layouts *)
+type const_layout =
+  | Any
+  | Value
+  | Void
+  | Immediate64
+  | Immediate
+  | Float64
+
+type layout_annotation = const_layout loc
+
+type label = string
+
+type arg_label =
+    Nolabel
+  | Labelled of string (** [label:T -> ...] *)
+  | Optional of string (** [?label:T -> ...] *)
 
 type variance =
   | Covariant
   | Contravariant
   | NoVariance
--- parser-upstream/lexer.mll
+++ parser-standard/lexer.mll
@@@@
     "done", DONE;
     "downto", DOWNTO;
     "else", ELSE;
     "end", END;
     "exception", EXCEPTION;
+    "exclave_", EXCLAVE;
     "external", EXTERNAL;
     "false", FALSE;
     "for", FOR;
     "fun", FUN;
     "function", FUNCTION;
     "functor", FUNCTOR;
+    "global_", GLOBAL;
     "if", IF;
     "in", IN;
     "include", INCLUDE;
     "inherit", INHERIT;
     "initializer", INITIALIZER;
     "lazy", LAZY;
     "let", LET;
+    "local_", LOCAL;
     "match", MATCH;
     "method", METHOD;
     "module", MODULE;
     "mutable", MUTABLE;
     "new", NEW;
@@@@
     "lsl", INFIXOP4("lsl");
     "lsr", INFIXOP4("lsr");
     "asr", INFIXOP4("asr")
 ]
 
+let lookup_keyword name =
+  match Hashtbl.find keyword_table name with
+  | kw -> kw
+  | exception Not_found ->
+     LIDENT name
+
 (* To buffer string literals *)
 
 let string_buffer = Buffer.create 256
 let reset_string_buffer () = Buffer.reset string_buffer
 let get_stored_string () = Buffer.contents string_buffer
@@@@
 let in_comment () = !comment_start_loc <> []
 let is_in_string = ref false
 let in_string () = !is_in_string
 let print_warnings = ref true
 
+let at_beginning_of_line pos = (pos.pos_cnum = pos.pos_bol)
+
+(* See the comment on the [directive] lexer. *)
+type directive_lexing_already_consumed =
+   | Hash
+   | Hash_and_line_num of { line_num : string }
+
+type deferred_token =
+  { token : token
+  ; start_pos : Lexing.position
+  ; end_pos : Lexing.position
+  }
+
+(* This queue will only ever have 0 or 1 elements in it. We use it
+   instead of an [option ref] for its convenient interface.
+*)
+let deferred_tokens : deferred_token Queue.t = Queue.create ()
+
+(* Effectively splits the text in the lexer's current "window" (defined below)
+   into two halves. The current call to the lexer will return the first half of
+   the text in the window, and the next call to the lexer will return the second
+   half (of length [len]) of the text in the window.
+
+   "window" refers to the text matched by a production of the lexer. It spans
+   from [lexer.lex_start_p] to [lexer.lex_curr_p].
+
+   The function accomplishes this splitting by doing two things:
+    - It sets the current window of the lexbuf to only account for the
+      first half of the text. (The first half is of length: |text|-len.)
+    - It enqueues a token into [deferred_tokens] such that, the next time the
+      lexer is called, it will return the specified [token] *and* set the window
+      of the lexbuf to account for the second half of the text. (The second half
+      is of length: |text|.)
+
+   This business with setting the window of the lexbuf is only so that error
+   messages point at the right place in the program text.
+*)
+let enqueue_token_from_end_of_lexbuf_window (lexbuf : Lexing.lexbuf) token ~len =
+  let suffix_end = lexbuf.lex_curr_p in
+  let suffix_start =
+    { suffix_end with pos_cnum = suffix_end.pos_cnum - len }
+  in
+  lexbuf.lex_curr_p <- suffix_start;
+  Queue.add
+    { token; start_pos = suffix_start; end_pos = suffix_end }
+    deferred_tokens
+
+(* Note [Lexing hack for float#]
+   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+   This note describes a non-backward-compatible Jane Street--internal change to
+   the lexer.
+
+   We want the lexer to lex [float#] differently than [float #]. [float#] is the
+   new syntax for the unboxed float type. It veers close to the syntax for the
+   type of all objects belonging to a class [c], which is [#c]. The way we
+   navigate this veering is by producing the following tokens for these source
+   program examples, where LIDENT(s) is an LIDENT with text [s].
+
+   float#c   ==> LIDENT(float) HASH_SUFFIX LIDENT(c)
+   float# c  ==> LIDENT(float) HASH_SUFFIX LIDENT(c)
+   float # c ==> LIDENT(float) HASH LIDENT(c)
+   float #c  ==> LIDENT(float) HASH LIDENT(c)
+
+   (A) The parser interprets [LIDENT(float) HASH_SUFFIX LIDENT(c)] as
+       "the type constructor [c] applied to the unboxed float type."
+   (B) The parser interprets [LIDENT(float) HASH LIDENT(c)] as
+       "the type constructor [#c] applied to the usual boxed float type."
+
+   This is not a backward-compatible change. In upstream ocaml, the lexer
+   produces [LIDENT(float) HASH LIDENT(c)] for all the above source programs.
+
+   But, this isn't problematic: everybody puts a space before '#c' to mean (B).
+   No existing code writes things like [float#c] or indeed [float# c].
+
+   We accomplish this hack by setting some global mutable state upon seeing
+   an identifier immediately followed by a hash. When that state is set, we
+   will produce [HASH_SUFFIX] the next time the lexer is called. This is
+   done in [enqueue_hash_suffix_from_end_of_lexbuf_window].
+
+   Note [Lexing hack for hash operators]
+   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+   To complicate the above story, we don't want to treat the # in the
+   below program as HASH_SUFFIX:
+
+   x#~#y
+
+   We instead want:
+
+   x#~#y ==> LIDENT(x) HASHOP(#~#) LIDENT(y)
+
+   This is to allow for infix hash operators. We add an additional hack, in
+   the style of Note [Lexing hack for float#], where the lexer consumes [x#~#]
+   all at once, but produces LIDENT(x) from the current call to the lexer and
+   HASHOP(#~#) from the next call to the lexer. This is done in
+   [enqueue_hashop_from_end_of_lexbuf_window].
+ *)
+
+let enqueue_hash_suffix_from_end_of_lexbuf_window lexbuf =
+  enqueue_token_from_end_of_lexbuf_window lexbuf HASH_SUFFIX ~len:1
+
+let enqueue_hashop_from_end_of_lexbuf_window lexbuf ~hashop =
+  enqueue_token_from_end_of_lexbuf_window lexbuf (HASHOP hashop)
+    ~len:(String.length hashop)
+
 (* Escaped chars are interpreted in strings unless they are in comments. *)
 let store_escaped_char lexbuf c =
   if in_comment () then store_lexeme lexbuf else store_string_char c
 
 let store_escaped_uchar lexbuf u =
@@@@
   { start_loc with Location.loc_end = end_loc.Location.loc_end }
 
 let error lexbuf e = raise (Error(e, Location.curr lexbuf))
 let error_loc loc e = raise (Error(e, loc))
 
+let directive_error
+    (lexbuf : Lexing.lexbuf) explanation ~directive ~already_consumed
+  =
+  let directive_prefix =
+    match already_consumed with
+    | Hash -> "#"
+    | Hash_and_line_num { line_num } -> "#" ^ line_num
+  in
+  (* Set the lexbuf's current window to extend to the start of
+     the directive so the error message's location is more accurate.
+  *)
+  lexbuf.lex_start_p <-
+    { lexbuf.lex_start_p with
+      pos_cnum =
+        lexbuf.lex_start_p.pos_cnum - String.length directive_prefix
+    };
+  error lexbuf
+    (Invalid_directive (directive_prefix ^ directive, Some explanation))
+
 (* to translate escape sequences *)
 
 let digit_value c =
   match c with
   | 'a' .. 'f' -> 10 + Char.code c - Char.code 'a'
@@@@
 let is_keyword name = Hashtbl.mem keyword_table name
 
 let check_label_name lexbuf name =
   if is_keyword name then error lexbuf (Keyword_as_label name)
 
+(* To "unlex" a few characters *)
+let set_lexeme_length buf n = (
+  let open Lexing in
+  if n < 0 then
+    invalid_arg "set_lexeme_length: offset should be positive";
+  if n > buf.lex_curr_pos - buf.lex_start_pos then
+    invalid_arg "set_lexeme_length: offset larger than lexeme";
+  buf.lex_curr_pos <- buf.lex_start_pos + n;
+  buf.lex_curr_p <- {buf.lex_start_p
+                     with pos_cnum = buf.lex_abs_pos + buf.lex_curr_pos};
+)
+
+let disambiguate lexbuf txt =
+  let pos = ref 0 in
+  let len = String.length txt in
+  let is_digit c = c >= '0' && c <= '9' in
+  while !pos < len && is_digit txt.[!pos] do incr pos done;
+  let txt =
+    if !pos < len then (
+      set_lexeme_length lexbuf !pos;
+      String.sub txt 0 !pos
+    ) else
+      txt
+  in
+  TYPE_DISAMBIGUATOR txt
+
+let try_disambiguate lexbuf = function
+  | INT (txt, None) -> Some (disambiguate lexbuf txt)
+  | FLOAT (txt, _)  -> Some (disambiguate lexbuf txt)
+  | _ -> None
+
 (* Update the current location with file name and line number. *)
 
 let update_loc lexbuf file line absolute chars =
   let pos = lexbuf.lex_curr_p in
   let new_file = match file with
@@@@
   in
     add_comment com
 
 let comments () = List.rev !comment_list
 
+let float ~maybe_hash lit modifier =
+  match maybe_hash with
+  | "#" -> HASH_FLOAT (lit, modifier)
+  | "" -> FLOAT (lit, modifier)
+  | unexpected -> fatal_error ("expected # or empty string: " ^ unexpected)
+
+let int ~maybe_hash lit modifier =
+  match maybe_hash with
+  | "#" -> HASH_INT (lit, modifier)
+  | "" -> INT (lit, modifier)
+  | unexpected -> fatal_error ("expected # or empty string: " ^ unexpected)
+
 (* Error report *)
 
 open Format
 
 let prepare_error loc = function
@@@@
       { check_label_name lexbuf name;
         OPTLABEL name }
   | "?" (lowercase_latin1 identchar_latin1 * as name) ':'
       { warn_latin1 lexbuf;
         OPTLABEL name }
+  (* Lowercase identifiers are split into 3 cases, and the order matters
+     (longest to shortest).
+  *)
+  | (lowercase identchar * as name) ('#' symbolchar_or_hash+ as hashop)
+      (* See Note [Lexing hack for hash operators] *)
+      { enqueue_hashop_from_end_of_lexbuf_window lexbuf ~hashop;
+        lookup_keyword name }
+  | (lowercase identchar * as name) '#'
+      (* See Note [Lexing hack for float#] *)
+      { enqueue_hash_suffix_from_end_of_lexbuf_window lexbuf;
+        lookup_keyword name }
   | lowercase identchar * as name
       { try Hashtbl.find keyword_table name
         with Not_found -> LIDENT name }
+  (* Lowercase latin1 identifiers are split into 3 cases, and the order matters
+     (longest to shortest).
+  *)
+  | (lowercase_latin1 identchar_latin1 * as name)
+      ('#' symbolchar_or_hash+ as hashop)
+      (* See Note [Lexing hack for hash operators] *)
+      { warn_latin1 lexbuf;
+        enqueue_hashop_from_end_of_lexbuf_window lexbuf ~hashop;
+        LIDENT name }
+  | (lowercase_latin1 identchar_latin1 * as name) '#'
+      (* See Note [Lexing hack for float#] *)
+      { warn_latin1 lexbuf;
+        enqueue_hash_suffix_from_end_of_lexbuf_window lexbuf;
+        LIDENT name }
   | lowercase_latin1 identchar_latin1 * as name
       { warn_latin1 lexbuf; LIDENT name }
   | uppercase identchar * as name
       { UIDENT name } (* No capitalized keywords *)
   | uppercase_latin1 identchar_latin1 * as name
       { warn_latin1 lexbuf; UIDENT name }
-  | int_literal as lit { INT (lit, None) }
-  | (int_literal as lit) (literal_modifier as modif)
-      { INT (lit, Some modif) }
-  | float_literal | hex_float_literal as lit
-      { FLOAT (lit, None) }
-  | (float_literal | hex_float_literal as lit) (literal_modifier as modif)
-      { FLOAT (lit, Some modif) }
-  | (float_literal | hex_float_literal | int_literal) identchar+ as invalid
+  (* This matches either an integer literal or a directive. If the text "#2"
+     appears at the beginning of a line that lexes as a directive, then it
+     should be treated as a directive and not an unboxed int. This is acceptable
+     because "#2" isn't a valid unboxed int anyway because it lacks a suffix;
+     the parser rejects unboxed-ints-lacking-suffixes with a more descriptive
+     error message.
+  *)
+  | ('#'? as maybe_hash) (int_literal as lit)
+      { if at_beginning_of_line lexbuf.lex_start_p && maybe_hash = "#" then
+          try directive (Hash_and_line_num { line_num = lit }) lexbuf
+          with Failure _ -> int ~maybe_hash lit None
+        else int ~maybe_hash lit None
+      }
+  | ('#'? as maybe_hash) (int_literal as lit) (literal_modifier as modif)
+      { int ~maybe_hash lit (Some modif) }
+  | ('#'? as maybe_hash)
+    (float_literal | hex_float_literal as lit)
+      { float ~maybe_hash lit None }
+  | ('#'? as maybe_hash)
+    (float_literal | hex_float_literal as lit) (literal_modifier as modif)
+      { float ~maybe_hash lit (Some modif) }
+  | '#'? (float_literal | hex_float_literal | int_literal) identchar+ as invalid
       { error lexbuf (Invalid_literal invalid) }
   | "\""
       { let s, loc = wrap_string_lexer string lexbuf in
         STRING (s, loc, None) }
   | "{" (lowercase* as delim) "|"
@@@@
         let curpos = lexbuf.lex_curr_p in
         lexbuf.lex_curr_p <- { curpos with pos_cnum = curpos.pos_cnum - 1 };
         STAR
       }
   | "#"
-      { let at_beginning_of_line pos = (pos.pos_cnum = pos.pos_bol) in
-        if not (at_beginning_of_line lexbuf.lex_start_p)
+      { if not (at_beginning_of_line lexbuf.lex_start_p)
         then HASH
-        else try directive lexbuf with Failure _ -> HASH
+        else try directive Hash lexbuf with Failure _ -> HASH
       }
   | "&"  { AMPERSAND }
   | "&&" { AMPERAMPER }
   | "`"  { BACKQUOTE }
   | "\'" { QUOTE }
@@@@
   | "<"  { LESS }
   | "<-" { LESSMINUS }
   | "="  { EQUAL }
   | "["  { LBRACKET }
   | "[|" { LBRACKETBAR }
+  | "[:" { LBRACKETCOLON }
   | "[<" { LBRACKETLESS }
   | "[>" { LBRACKETGREATER }
   | "]"  { RBRACKET }
   | "{"  { LBRACE }
   | "{<" { LBRACELESS }
   | "|"  { BAR }
   | "||" { BARBAR }
   | "|]" { BARRBRACKET }
+  | ":]" { COLONRBRACKET }
   | ">"  { GREATER }
   | ">]" { GREATERRBRACKET }
   | "}"  { RBRACE }
   | ">}" { GREATERRBRACE }
   | "[@" { LBRACKETAT }
@@@@
   | ['+' '-'] symbolchar * as op
             { INFIXOP2 op }
   | "**" symbolchar * as op
             { INFIXOP4 op }
   | '%'     { PERCENT }
+  | '/'     { SLASH }
   | ['*' '/' '%'] symbolchar * as op
             { INFIXOP3 op }
   | '#' symbolchar_or_hash + as op
             { HASHOP op }
   | "let" kwdopchar dotsymbolchar * as op
@@@@
             { ANDOP op }
   | eof { EOF }
   | (_ as illegal_char)
       { error lexbuf (Illegal_character illegal_char) }
 
-and directive = parse
-  | ([' ' '\t']* (['0'-'9']+ as num) [' ' '\t']*
-        ("\"" ([^ '\010' '\013' '\"' ] * as name) "\"") as directive)
+(* An example of a directive is:
+
+#4 "filename.ml"
+
+   Here, 4 is the line number and filename.ml is the file name. The '#' must
+   appear in column 0.
+
+   The [directive] lexer is called when some portion of the start of
+   the line was already consumed, either just the '#' or the '#4'. That's
+   indicated by the [already_consumed] argument. The caller is responsible
+   for checking that the '#' appears in column 0.
+
+   The [directive] lexer always attempts to read the line number from the
+   lexbuf. It expects to receive a line number from exactly one source (either
+   the lexbuf or the [already_consumed] argument, but not both) and will fail if
+   this isn't the case.
+*)
+and directive already_consumed = parse
+  | ([' ' '\t']* (['0'-'9']+? as _line_num_opt) [' ' '\t']*
+     ("\"" ([^ '\010' '\013' '\"' ] * as _name) "\"") as directive)
         [^ '\010' '\013'] *
       {
-        match int_of_string num with
-        | exception _ ->
-            (* PR#7165 *)
-            let explanation = "line number out of range" in
-            error lexbuf (Invalid_directive ("#" ^ directive, Some explanation))
-        | line_num ->
-           (* Documentation says that the line number should be
-              positive, but we have never guarded against this and it
-              might have useful hackish uses. *)
-            update_loc lexbuf (Some name) (line_num - 1) true 0;
-            token lexbuf
+        (* Line directives are not preserved by the lexer so we error out. *)
+        let explanation = "line directives are not supported" in
+        directive_error lexbuf explanation ~already_consumed ~directive
       }
 and comment = parse
     "(*"
       { comment_start_loc := (Location.curr lexbuf) :: !comment_start_loc;
         store_lexeme lexbuf;
@@@@
   | "#!" [^ '\n']* '\n'
       { update_loc lexbuf None 1 false 0 }
   | "" { () }
 
 {
+  let token lexbuf =
+    match Queue.take_opt deferred_tokens with
+    | None -> token lexbuf
+    | Some { token; start_pos; end_pos } ->
+        lexbuf.lex_start_p <- start_pos;
+        lexbuf.lex_curr_p <- end_pos;
+        token
 
   let token_with_comments lexbuf =
     match !preprocessor with
     | None -> token lexbuf
     | Some (_init, preprocess) -> preprocess token lexbuf
--- parser-upstream/parse.ml
+++ parser-standard/parse.ml
@@@@
 let maybe_skip_phrase lexbuf =
   match !last_token with
   | Parser.SEMISEMI | Parser.EOF -> ()
   | _ -> skip_phrase lexbuf
 
-type 'a parser =
-  (Lexing.lexbuf -> Parser.token) -> Lexing.lexbuf -> 'a
+type 'a parser = Lexing.position -> 'a Parser.MenhirInterpreter.checkpoint
 
 let wrap (parser : 'a parser) lexbuf : 'a =
   try
     Docstrings.init ();
     Lexer.init ();
-    let ast = parser token lexbuf in
+    let open Parser.MenhirInterpreter in
+    let rec fix_resume = function
+      | InputNeeded _ | Accepted _ | Rejected | HandlingError _ as cp -> cp
+      | Shifting (_, _, _) | AboutToReduce (_, _) as cp ->
+        fix_resume (resume ~strategy:`Simplified cp)
+    in
+    let rec offer_input lexbuf cp tok =
+      let ptok = Lexing.(tok, lexbuf.lex_start_p, lexbuf.lex_curr_p) in
+      match fix_resume (offer cp ptok) with
+      | InputNeeded _ as cp ->
+          offer_input lexbuf cp (token lexbuf)
+      | Accepted x -> Some x
+      | Rejected -> None
+      | Shifting (_, _, _) | AboutToReduce (_, _) ->
+          assert false
+      | HandlingError _ as cp' ->
+        match Lexer.try_disambiguate lexbuf tok with
+        | Some tok' -> offer_input lexbuf cp tok'
+        | None -> main_loop lexbuf cp'
+    and main_loop lexbuf = function
+      | InputNeeded _ as cp ->
+          offer_input lexbuf cp (token lexbuf)
+      | Accepted x -> Some x
+      | Rejected -> None
+      | Shifting (_, _, _) | AboutToReduce (_, _) | HandlingError _ as cp ->
+        main_loop lexbuf (resume ~strategy:`Simplified cp)
+    in
+    let ast =
+      match main_loop lexbuf (parser lexbuf.Lexing.lex_curr_p) with
+      | Some ast -> ast
+      | None -> raise Parsing.Parse_error
+    in
     Parsing.clear_parser();
     Docstrings.warn_bad_docstrings ();
     last_token := Parser.EOF;
     ast
   with
@@@@
      a production whose semantic action raises an exception.
 
    In either case, the parser will not attempt to read one token past
    the syntax error. *)
 
-let implementation = wrap Parser.implementation
-and interface = wrap Parser.interface
-and toplevel_phrase = wrap Parser.toplevel_phrase
-and use_file = wrap Parser.use_file
-and core_type = wrap Parser.parse_core_type
-and expression = wrap Parser.parse_expression
-and pattern = wrap Parser.parse_pattern
-let module_type = wrap Parser.parse_module_type
-let module_expr = wrap Parser.parse_module_expr
-
-let longident = wrap Parser.parse_any_longident
-let val_ident = wrap Parser.parse_val_longident
-let constr_ident= wrap Parser.parse_constr_longident
-let extended_module_path = wrap Parser.parse_mod_ext_longident
-let simple_module_path = wrap Parser.parse_mod_longident
-let type_ident = wrap Parser.parse_mty_longident
+let implementation = wrap Parser.Incremental.implementation
+and interface = wrap Parser.Incremental.interface
+and toplevel_phrase = wrap Parser.Incremental.toplevel_phrase
+and use_file = wrap Parser.Incremental.use_file
+and core_type = wrap Parser.Incremental.parse_core_type
+and expression = wrap Parser.Incremental.parse_expression
+and pattern = wrap Parser.Incremental.parse_pattern
+let module_type = wrap Parser.Incremental.parse_module_type
+let module_expr = wrap Parser.Incremental.parse_module_expr
+
+let longident = wrap Parser.Incremental.parse_any_longident
+let val_ident = wrap Parser.Incremental.parse_val_longident
+let constr_ident= wrap Parser.Incremental.parse_constr_longident
+let extended_module_path = wrap Parser.Incremental.parse_mod_ext_longident
+let simple_module_path = wrap Parser.Incremental.parse_mod_longident
+let type_ident = wrap Parser.Incremental.parse_mty_longident
 
 (* Error reporting for Syntaxerr *)
 (* The code has been moved here so that one can reuse Pprintast.tyvar *)
 
 let prepare_error err =
--- parser-upstream/parser.mly
+++ parser-standard/parser.mly
@@@@
   Location.loc_end = endpos;
   Location.loc_ghost = true;
 }
 
 let mktyp ~loc ?attrs d = Typ.mk ~loc:(make_loc loc) ?attrs d
-let mkpat ~loc d = Pat.mk ~loc:(make_loc loc) d
-let mkexp ~loc d = Exp.mk ~loc:(make_loc loc) d
+let mkpat ~loc ?attrs d = Pat.mk ~loc:(make_loc loc) ?attrs d
+let mkexp ~loc ?attrs d = Exp.mk ~loc:(make_loc loc) ?attrs d
 let mkmty ~loc ?attrs d = Mty.mk ~loc:(make_loc loc) ?attrs d
 let mksig ~loc d = Sig.mk ~loc:(make_loc loc) d
 let mkmod ~loc ?attrs d = Mod.mk ~loc:(make_loc loc) ?attrs d
 let mkstr ~loc d = Str.mk ~loc:(make_loc loc) d
 let mkclass ~loc ?attrs d = Cl.mk ~loc:(make_loc loc) ?attrs d
@@@@
   (Pstr_primitive vd, ext)
 let pstr_type ((nr, ext), tys) =
   (Pstr_type (nr, tys), ext)
 let pstr_exception (te, ext) =
   (Pstr_exception te, ext)
-let pstr_include (body, ext) =
-  (Pstr_include body, ext)
 let pstr_recmodule (ext, bindings) =
   (Pstr_recmodule bindings, ext)
 
 let psig_typext (te, ext) =
   (Psig_typext te, ext)
@@@@
 let psig_typesubst ((nr, ext), tys) =
   assert (nr = Recursive); (* see [no_nonrec_flag] *)
   (Psig_typesubst tys, ext)
 let psig_exception (te, ext) =
   (Psig_exception te, ext)
-let psig_include (body, ext) =
-  (Psig_include body, ext)
 
 let mkctf ~loc ?attrs ?docs d =
   Ctf.mk ~loc:(make_loc loc) ?attrs ?docs d
 let mkcf ~loc ?attrs ?docs d =
   Cf.mk ~loc:(make_loc loc) ?attrs ?docs d
@@@@
   AST node, then the location must be real; in all other cases,
   it must be ghost.
 *)
 let ghexp ~loc d = Exp.mk ~loc:(ghost_loc loc) d
 let ghpat ~loc d = Pat.mk ~loc:(ghost_loc loc) d
-let ghtyp ~loc d = Typ.mk ~loc:(ghost_loc loc) d
+let ghtyp ~loc ?attrs d = Typ.mk ~loc:(ghost_loc loc) ?attrs d
 let ghloc ~loc d = { txt = d; loc = ghost_loc loc }
 let ghstr ~loc d = Str.mk ~loc:(ghost_loc loc) d
 let ghsig ~loc d = Sig.mk ~loc:(ghost_loc loc) d
 
 let mkinfix arg1 op arg2 =
@@@@
   else "-" ^ f
 
 let mkuminus ~oploc name arg =
   match name, arg.pexp_desc with
   | "-", Pexp_constant(Pconst_integer (n,m)) ->
-      Pexp_constant(Pconst_integer(neg_string n,m))
+      Pexp_constant(Pconst_integer(neg_string n,m)), arg.pexp_attributes
   | ("-" | "-."), Pexp_constant(Pconst_float (f, m)) ->
-      Pexp_constant(Pconst_float(neg_string f, m))
+      Pexp_constant(Pconst_float(neg_string f, m)), arg.pexp_attributes
   | _ ->
-      Pexp_apply(mkoperator ~loc:oploc ("~" ^ name), [Nolabel, arg])
+      Pexp_apply(mkoperator ~loc:oploc ("~" ^ name), [Nolabel, arg]), []
 
 let mkuplus ~oploc name arg =
   let desc = arg.pexp_desc in
   match name, desc with
   | "+", Pexp_constant(Pconst_integer _)
-  | ("+" | "+."), Pexp_constant(Pconst_float _) -> desc
+  | ("+" | "+."), Pexp_constant(Pconst_float _) -> desc, arg.pexp_attributes
   | _ ->
-      Pexp_apply(mkoperator ~loc:oploc ("~" ^ name), [Nolabel, arg])
+      Pexp_apply(mkoperator ~loc:oploc ("~" ^ name), [Nolabel, arg]), []
+module Local_syntax_category = struct
+  type _ t =
+    | Type : core_type t
+    | Expression : expression t
+    | Pattern : pattern t
+    | Synthesized_constraint : expression t
+end
+
+let local_if : type ast. ast Local_syntax_category.t -> _ -> _ -> ast -> ast =
+  fun cat is_local sloc x ->
+  if is_local then
+    let make : loc:_ -> attrs:_ -> ast = match cat with
+      | Type       -> Jane_syntax.Local.type_of (Ltyp_local x)
+      | Expression -> Jane_syntax.Local.expr_of (Lexp_local x)
+      | Pattern    -> Jane_syntax.Local.pat_of  (Lpat_local x)
+      | Synthesized_constraint ->
+        Jane_syntax.Local.expr_of (Lexp_constrain_local x)
+    in
+    make ~loc:(make_loc sloc) ~attrs:[]
+  else
+    x
+
+let global_if global_flag sloc carg =
+  match global_flag with
+  | Global ->
+      Jane_syntax.Local.constr_arg_of ~loc:(make_loc sloc) (Lcarg_global carg)
+  | Nothing ->
+      carg
 
 (* TODO define an abstraction boundary between locations-as-pairs
    and locations-as-Location.t; it should be clear when we move from
    one world to the other *)
 
@@@@
 
 let unclosed opening_name opening_loc closing_name closing_loc =
   raise(Syntaxerr.Error(Syntaxerr.Unclosed(make_loc opening_loc, opening_name,
                                            make_loc closing_loc, closing_name)))
 
-let expecting loc nonterm =
-    raise Syntaxerr.(Error(Expecting(make_loc loc, nonterm)))
-
-let removed_string_set loc =
-  raise(Syntaxerr.Error(Syntaxerr.Removed_string_set(make_loc loc)))
+(* Normal mutable arrays and immutable arrays are parsed identically, just with
+   different delimiters.  The parsing is done by the [array_exprs] rule, and the
+   [Generic_array] module provides (1) a type representing the possible results,
+   and (2) a function for going from that type to an AST fragment representing
+   an array. *)
+module Generic_array = struct
+  (** The three possible ways to parse an array (writing [[? ... ?]] for either
+      [[| ... |]] or [[: ... :]]): *)
+  type (_, _) t =
+    | Literal : 'ast list -> ('ast, 'ast_desc) t
+    (** A plain array literal/pattern, [[? x; y; z ?]] *)
+    | Opened_literal : open_declaration *
+                       Lexing.position *
+                       Lexing.position *
+                       expression list
+                     -> (expression, expression_desc) t
+    (** An array literal with a local open, [Module.[? x; y; z ?]] (only valid in
+        expressions) *)
+    | Unclosed : (Lexing.position * Lexing.position) *
+                 (Lexing.position * Lexing.position)
+               -> (_, _) t
+    (** Parse error: an unclosed array literal, [\[? x; y; z] with no closing
+        [?\]]. *)
+
+  let to_ast (type ast ast_desc)
+             (open_ : string) (close : string)
+             (array : ast list -> ast_desc)
+        : (ast, ast_desc) t -> ast_desc = function
+    | Literal elts ->
+        array elts
+    | Opened_literal(od, startpos, endpos, elts) ->
+        (Pexp_open(od, mkexp ~loc:(startpos, endpos) (array elts)) : ast_desc)
+    | Unclosed(startpos, endpos) ->
+        unclosed open_ startpos close endpos
+
+  let expression : _ -> _ -> _ -> (expression, expression_desc) t -> _ = to_ast
+  let pattern    : _ -> _ -> _ -> (pattern,    pattern_desc)    t -> _ = to_ast
+end
+
+let ppat_iarray loc elts =
+  (Jane_syntax.Immutable_arrays.pat_of
+     ~attrs:[]
+     ~loc:(make_loc loc)
+     (Iapat_immutable_array elts)).ppat_desc
+
+let expecting_loc (loc : Location.t) (nonterm : string) =
+    raise Syntaxerr.(Error(Expecting(loc, nonterm)))
+let expecting (loc : Lexing.position * Lexing.position) nonterm =
+     expecting_loc (make_loc loc) nonterm
 
 (* Using the function [not_expecting] in a semantic action means that this
    syntactic form is recognized by the parser but is in fact incorrect. This
    idiom is used in a few places to produce ad hoc syntax error messages. *)
 
@@@@
 
 let bigarray_untuplify = function
     { pexp_desc = Pexp_tuple explist; pexp_loc = _ } -> explist
   | exp -> [exp]
 
+(* Immutable array indexing is a regular operator, so it doesn't need a special
+   case here *)
 let builtin_arraylike_name loc _ ~assign paren_kind n =
   let opname = if assign then "set" else "get" in
   let opname = if !Clflags.unsafe then "unsafe_" ^ opname else opname in
   let prefix = match paren_kind with
     | Paren -> Lident "Array"
-    | Bracket ->
-        if assign then removed_string_set loc
-        else Lident "String"
+    | Bracket -> Lident "String"
     | Brace ->
        let submodule_name = match n with
          | One -> "Array1"
          | Two -> "Array2"
          | Three -> "Array3"
@@@@
   if !Clflags.applicative_functors
   then Lapply(p1, p2)
   else raise (Syntaxerr.Error(
                   Syntaxerr.Applicative_path (make_loc loc)))
 
-(* [loc_map] could be [Location.map]. *)
-let loc_map (f : 'a -> 'b) (x : 'a Location.loc) : 'b Location.loc =
-  { x with txt = f x.txt }
-
 let make_ghost x = { x with loc = { x.loc with loc_ghost = true }}
 
 let loc_last (id : Longident.t Location.loc) : string Location.loc =
-  loc_map Longident.last id
+  Location.map Longident.last id
 
 let loc_lident (id : string Location.loc) : Longident.t Location.loc =
-  loc_map (fun x -> Lident x) id
+  Location.map (fun x -> Lident x) id
 
 let exp_of_longident lid =
-  let lid = loc_map (fun id -> Lident (Longident.last id)) lid in
+  let lid = Location.map (fun id -> Lident (Longident.last id)) lid in
   Exp.mk ~loc:lid.loc (Pexp_ident lid)
 
 let exp_of_label lbl =
   Exp.mk ~loc:lbl.loc (Pexp_ident (loc_lident lbl))
 
 let pat_of_label lbl =
   Pat.mk ~loc:lbl.loc  (Ppat_var (loc_last lbl))
 
 let mk_newtypes ~loc newtypes exp =
-  let mkexp = mkexp ~loc in
-  List.fold_right (fun newtype exp -> mkexp (Pexp_newtype (newtype, exp)))
-    newtypes exp
+  let mk_one (name, layout) exp =
+    match layout with
+    | None -> mkexp ~loc (Pexp_newtype (name, exp))
+    | Some layout ->
+      Jane_syntax.Layouts.expr_of ~loc:(make_loc loc) ~attrs:[]
+        (Lexp_newtype (name, layout, exp))
+  in
+  List.fold_right mk_one newtypes exp
 
 let wrap_type_annotation ~loc newtypes core_type body =
-  let mkexp, ghtyp = mkexp ~loc, ghtyp ~loc in
   let mk_newtypes = mk_newtypes ~loc in
-  let exp = mkexp(Pexp_constraint(body,core_type)) in
+  let exp = mkexp ~loc (Pexp_constraint(body,core_type)) in
   let exp = mk_newtypes newtypes exp in
-  (exp, ghtyp(Ptyp_poly(newtypes, Typ.varify_constructors newtypes core_type)))
+  let inner_type = Typ.varify_constructors (List.map fst newtypes) core_type in
+  let ltyp =
+    Jane_syntax.Layouts.Ltyp_poly { bound_vars = newtypes; inner_type }
+  in
+  (exp,
+     Jane_syntax.Layouts.type_of
+       ~loc:(Location.ghostify (make_loc loc)) ~attrs:[] ltyp)
 
 let wrap_exp_attrs ~loc body (ext, attrs) =
   let ghexp = ghexp ~loc in
   (* todo: keep exact location for the entire attribute *)
   let body = {body with pexp_attributes = attrs @ body.pexp_attributes} in
   match ext with
   | None -> body
   | Some id -> ghexp(Pexp_extension (id, PStr [mkstrexp body []]))
 
-let mkexp_attrs ~loc d attrs =
-  wrap_exp_attrs ~loc (mkexp ~loc d) attrs
+let mkexp_attrs ~loc d ext_attrs =
+  wrap_exp_attrs ~loc (mkexp ~loc d) ext_attrs
 
 let wrap_typ_attrs ~loc typ (ext, attrs) =
   (* todo: keep exact location for the entire attribute *)
   let typ = {typ with ptyp_attributes = attrs @ typ.ptyp_attributes} in
   match ext with
@@@@
       pdir_name = name;
       pdir_arg = arg;
       pdir_loc = make_loc loc;
     }
 
+let check_layout ~loc id : const_layout =
+  match id with
+  | "any" -> Any
+  | "value" -> Value
+  | "void" -> Void
+  | "immediate64" -> Immediate64
+  | "immediate" -> Immediate
+  | "float64" -> Float64
+  | _ -> expecting_loc loc "layout"
+
+(* Unboxed literals *)
+
+(* CR layouts v2.5: The [unboxed_*] functions will both be improved and lose
+   their explicit assert once we have real unboxed literals in Jane syntax; they
+   may also get re-inlined at that point *)
+let unboxed_literals_extension = Language_extension.Layouts
+
+module Constant : sig
+  type t = private
+    | Value of constant
+    | Unboxed of Jane_syntax.Layouts.constant
+
+  type loc := Lexing.position * Lexing.position
+
+  val value : Parsetree.constant -> t
+  val unboxed : loc:loc -> Jane_syntax.Layouts.constant -> t
+  val to_expression : loc:loc -> t -> expression
+  val to_pattern : loc:loc -> t -> pattern
+  val assert_is_value : loc:loc -> where:string -> t -> constant
+end = struct
+  type t =
+    | Value of constant
+    | Unboxed of Jane_syntax.Layouts.constant
+
+  let value x = Value x
+
+  let assert_unboxed_literals ~loc =
+    Language_extension.(
+      Jane_syntax_parsing.assert_extension_enabled ~loc Layouts Alpha)
+
+  let unboxed ~loc x =
+    assert_unboxed_literals ~loc:(make_loc loc);
+    Unboxed x
+
+  let to_expression ~loc : t -> expression = function
+    | Value const_value ->
+        mkexp ~loc (Pexp_constant const_value)
+    | Unboxed const_unboxed ->
+      Jane_syntax.Layouts.expr_of
+        ~loc:(make_loc loc) ~attrs:[] (Lexp_constant const_unboxed)
+
+  let to_pattern ~loc : t -> pattern = function
+    | Value const_value ->
+        mkpat ~loc (Ppat_constant const_value)
+    | Unboxed const_unboxed ->
+      Jane_syntax.Layouts.pat_of
+        ~loc:(make_loc loc) ~attrs:[] (Lpat_constant const_unboxed)
+
+  let assert_is_value ~loc ~where : t -> Parsetree.constant = function
+    | Value x -> x
+    | Unboxed _ ->
+        not_expecting loc (Printf.sprintf "unboxed literal %s" where)
+end
+
+type sign = Positive | Negative
+
+let with_sign sign num =
+  match sign with
+  | Positive -> num
+  | Negative -> "-" ^ num
+
+let unboxed_int sloc int_loc sign (n, m) =
+  match m with
+  | Some m ->
+      Constant.unboxed ~loc:int_loc (Integer (with_sign sign n, m))
+  | None ->
+      if Language_extension.is_enabled unboxed_literals_extension then
+        expecting int_loc "unboxed integer literal with type-specifying suffix"
+      else
+        not_expecting sloc "line number directive"
+
+let unboxed_float sloc sign (f, m) =
+  Constant.unboxed ~loc:sloc (Float (with_sign sign f, m))
+
+(* Unboxed float type *)
+
+let assert_unboxed_float_type ~loc =
+    Language_extension.(
+      Jane_syntax_parsing.assert_extension_enabled ~loc Layouts Alpha)
+
+let unboxed_float_type sloc tys =
+  assert_unboxed_float_type ~loc:(make_loc sloc);
+  Ptyp_constr (mkloc (Lident "float#") (make_loc sloc), tys)
 %}
 
 /* Tokens */
 
 /* The alias that follows each token is used by Menhir when it needs to
@@@@
 %token CLASS                  "class"
 %token COLON                  ":"
 %token COLONCOLON             "::"
 %token COLONEQUAL             ":="
 %token COLONGREATER           ":>"
+%token COLONRBRACKET          ":]"
 %token COMMA                  ","
 %token CONSTRAINT             "constraint"
 %token DO                     "do"
 %token DONE                   "done"
 %token DOT                    "."
@@@@
 %token ELSE                   "else"
 %token END                    "end"
 %token EOF                    ""
 %token EQUAL                  "="
 %token EXCEPTION              "exception"
+%token EXCLAVE                "exclave_"
 %token EXTERNAL               "external"
 %token FALSE                  "false"
-%token <string * char option> FLOAT "42.0" (* just an example *)
+%token <string * char option> FLOAT      "42.0"  (* just an example *)
+%token <string * char option> HASH_FLOAT "#42.0" (* just an example *)
 %token FOR                    "for"
 %token FUN                    "fun"
 %token FUNCTION               "function"
 %token FUNCTOR                "functor"
+%token GLOBAL                 "global_"
 %token GREATER                ">"
 %token GREATERRBRACE          ">}"
 %token GREATERRBRACKET        ">]"
 %token IF                     "if"
 %token IN                     "in"
@@@@
 %token <string> DOTOP         ".+"
 %token <string> LETOP         "let*" (* just an example *)
 %token <string> ANDOP         "and*" (* just an example *)
 %token INHERIT                "inherit"
 %token INITIALIZER            "initializer"
-%token <string * char option> INT "42"  (* just an example *)
+%token <string * char option> INT      "42"   (* just an example *)
+%token <string * char option> HASH_INT "#42l" (* just an example *)
 %token <string> LABEL         "~label:" (* just an example *)
 %token LAZY                   "lazy"
 %token LBRACE                 "{"
 %token LBRACELESS             "{<"
 %token LBRACKET               "["
 %token LBRACKETBAR            "[|"
+%token LBRACKETCOLON          "[:"
 %token LBRACKETLESS           "[<"
 %token LBRACKETGREATER        "[>"
 %token LBRACKETPERCENT        "[%"
 %token LBRACKETPERCENTPERCENT "[%%"
 %token LESS                   "<"
 %token LESSMINUS              "<-"
 %token LET                    "let"
 %token <string> LIDENT        "lident" (* just an example *)
+%token LOCAL                  "local_"
 %token LPAREN                 "("
 %token LBRACKETAT             "[@"
 %token LBRACKETATAT           "[@@"
 %token LBRACKETATATAT         "[@@@"
 %token MATCH                  "match"
@@@@
 %token REC                    "rec"
 %token RPAREN                 ")"
 %token SEMI                   ";"
 %token SEMISEMI               ";;"
 %token HASH                   "#"
+%token HASH_SUFFIX            "# "
 %token <string> HASHOP        "##" (* just an example *)
 %token SIG                    "sig"
+%token SLASH                  "/"
 %token STAR                   "*"
 %token <string * Location.t * string option>
        STRING                 "\"hello\"" (* just an example *)
 %token <string * Location.t * string * Location.t * string option>
        QUOTED_STRING_EXPR     "{%hello|world|}"  (* just an example *)
@@@@
 %token <string * Location.t> COMMENT    "(* comment *)"
 %token <Docstrings.docstring> DOCSTRING "(** documentation *)"
 
 %token EOL                    "\\n"      (* not great, but EOL is unused *)
 
+%token <string> TYPE_DISAMBIGUATOR "2" (* just an example *)
+
 /* Precedences and associativities.
 
 Tokens and rules have precedences.  A reduce/reduce conflict is resolved
 in favor of the first rule (in source file order).  A shift/reduce conflict
 is resolved by comparing the precedence and associativity of the token to
@@@@
 */
 
 %nonassoc IN
 %nonassoc below_SEMI
 %nonassoc SEMI                          /* below EQUAL ({lbl=...; lbl=...}) */
-%nonassoc LET                           /* above SEMI ( ...; let ... in ...) */
+%nonassoc LET FOR                       /* above SEMI ( ...; let ... in ...) */
 %nonassoc below_WITH
 %nonassoc FUNCTION WITH                 /* below BAR  (match ... with ...) */
 %nonassoc AND             /* above WITH (module rec A: SIG with ... and ...) */
 %nonassoc THEN                          /* below ELSE (if ... then ...) */
 %nonassoc ELSE                          /* (if ... then ... else ...) */
@@@@
 %right    COLONEQUAL                    /* expr (e := e := e) */
 %nonassoc AS
 %left     BAR                           /* pattern (p|p|p) */
 %nonassoc below_COMMA
 %left     COMMA                         /* expr/expr_comma_list (e,e,e) */
+%nonassoc below_FUNCTOR                 /* include M */
+%nonassoc FUNCTOR                       /* include functor M */
 %right    MINUSGREATER                  /* function_type (t -> t -> t) */
 %right    OR BARBAR                     /* expr (e || e || e) */
 %right    AMPERSAND AMPERAMPER          /* expr (e && e && e) */
 %nonassoc below_EQUAL
 %left     INFIXOP0 EQUAL LESS GREATER   /* expr (e OP e OP e) */
 %right    INFIXOP1                      /* expr (e OP e OP e) */
 %nonassoc below_LBRACKETAT
 %nonassoc LBRACKETAT
 %right    COLONCOLON                    /* expr (e :: e :: e) */
 %left     INFIXOP2 PLUS PLUSDOT MINUS MINUSDOT PLUSEQ /* expr (e OP e OP e) */
-%left     PERCENT INFIXOP3 STAR                 /* expr (e OP e OP e) */
+%left     PERCENT SLASH INFIXOP3 STAR                 /* expr (e OP e OP e) */
 %right    INFIXOP4                      /* expr (e OP e OP e) */
 %nonassoc prec_unary_minus prec_unary_plus /* unary - */
 %nonassoc prec_constant_constructor     /* cf. simple_expr (C versus C x) */
 %nonassoc prec_constr_appl              /* above AS BAR COLONCOLON COMMA */
 %nonassoc below_HASH
-%nonassoc HASH                         /* simple_expr/toplevel_directive */
+%nonassoc HASH HASH_SUFFIX              /* simple_expr/toplevel_directive */
 %left     HASHOP
 %nonassoc below_DOT
 %nonassoc DOT DOTOP
 /* Finally, the first tokens of simple_expr are above everything else. */
-%nonassoc BACKQUOTE BANG BEGIN CHAR FALSE FLOAT INT OBJECT
-          LBRACE LBRACELESS LBRACKET LBRACKETBAR LIDENT LPAREN
-          NEW PREFIXOP STRING TRUE UIDENT
+%nonassoc BACKQUOTE BANG BEGIN CHAR FALSE FLOAT HASH_FLOAT INT HASH_INT OBJECT
+          LBRACE LBRACELESS LBRACKET LBRACKETBAR LBRACKETCOLON LIDENT LPAREN
+          NEW PREFIXOP STRING TRUE UIDENT UNDERSCORE
           LBRACKETPERCENT QUOTED_STRING_EXPR
 
 
 /* Entry points */
 
@@@@
     { wrap_mksig_ext ~loc:$sloc $1 }
 
 %inline mk_directive_arg(symb): symb
     { mk_directive_arg ~loc:$sloc $1 }
 
+%inline mktyp_jane_syntax_ltyp(symb): symb
+    { Jane_syntax.Layouts.type_of ~loc:(make_loc $sloc) ~attrs:[] $1 }
+
 /* Generic definitions */
 
 (* [iloption(X)] recognizes either nothing or [X]. Assuming [X] produces
    an OCaml list, it produces an OCaml list, too. *)
 
@@@@
         { (* TODO review mkmod location *)
           Pmod_apply(me1, mkmod ~loc:$sloc (Pmod_structure [])) }
     | (* An extension. *)
       ex = extension
         { Pmod_extension ex }
+    | (* A hole. *)
+      UNDERSCORE
+        { Pmod_hole }
     )
     { $1 }
 ;
 
 (* A parenthesized module expression is a module expression that begins
@@@@
         { let (body, ext) = $1 in (Pstr_open body, ext) }
     | class_declarations
         { let (ext, l) = $1 in (Pstr_class l, ext) }
     | class_type_declarations
         { let (ext, l) = $1 in (Pstr_class_type l, ext) }
-    | include_statement(module_expr)
-        { pstr_include $1 }
     )
     { $1 }
+  | include_statement(module_expr)
+      { let is_functor, incl, ext = $1 in
+        let item =
+          if is_functor
+          then Jane_syntax.Include_functor.str_item_of ~loc:(make_loc $sloc)
+                 (Ifstr_include_functor incl)
+          else mkstr ~loc:$sloc (Pstr_include incl)
+        in
+        wrap_str_ext ~loc:$sloc item ext
+      }
 ;
 
 (* A single module binding. *)
 %inline module_binding:
   MODULE
@@@@
 
 (* -------------------------------------------------------------------------- *)
 
 (* Shared material between structures and signatures. *)
 
+include_maybe_functor:
+  | INCLUDE %prec below_FUNCTOR
+      { false }
+  | INCLUDE FUNCTOR
+      { true }
+;
+
 (* An [include] statement can appear in a structure or in a signature,
    which is why this definition is parameterized. *)
 %inline include_statement(thing):
-  INCLUDE
+  is_functor = include_maybe_functor
   ext = ext
   attrs1 = attributes
   thing = thing
   attrs2 = post_item_attributes
   {
     let attrs = attrs1 @ attrs2 in
     let loc = make_loc $sloc in
     let docs = symbol_docs $sloc in
-    Incl.mk thing ~attrs ~loc ~docs, ext
+    let incl = Incl.mk thing ~attrs ~loc ~docs in
+    is_functor, incl, ext
   }
 ;
 
 (* A module type declaration. *)
 module_type_declaration:
@@@@
         { Pmty_alias $3 } */
     | extension
         { Pmty_extension $1 }
     )
     { $1 }
+  | module_type WITH mkrhs(mod_ext_longident)
+      { Jane_syntax.Strengthen.mty_of ~loc:(make_loc $sloc) ~attrs:[]
+          { mty = $1; mod_id = $3 } }
 ;
 (* A signature, which appears between SIG and END (among other places),
    is a list of signature elements. *)
 signature:
   extra_sig(flatten(signature_element*))
@@@@
         { let (body, ext) = $1 in (Psig_modtype body, ext) }
     | module_type_subst
         { let (body, ext) = $1 in (Psig_modtypesubst body, ext) }
     | open_description
         { let (body, ext) = $1 in (Psig_open body, ext) }
-    | include_statement(module_type)
-        { psig_include $1 }
     | class_descriptions
         { let (ext, l) = $1 in (Psig_class l, ext) }
     | class_type_declarations
         { let (ext, l) = $1 in (Psig_class_type l, ext) }
     )
     { $1 }
+  | include_statement(module_type)
+      { let is_functor, incl, ext = $1 in
+        let item =
+          if is_functor
+          then Jane_syntax.Include_functor.sig_item_of ~loc:(make_loc $sloc)
+                 (Ifsig_include_functor incl)
+          else mksig ~loc:$sloc (Psig_include incl)
+        in
+        wrap_sig_ext ~loc:$sloc item ext
+      }
+
+;
 
 (* A module declaration. *)
 %inline module_declaration:
   MODULE
   ext = ext attrs1 = attributes
@@@@
     COLON poly_type EQUAL seq_expr
       { let poly_exp =
           let loc = ($startpos($6), $endpos($8)) in
           ghexp ~loc (Pexp_poly($8, Some $6)) in
         ($4, $3, Cfk_concrete ($1, poly_exp)), $2 }
-  | override_flag attributes private_flag mkrhs(label) COLON TYPE lident_list
+  | override_flag attributes private_flag mkrhs(label) COLON TYPE newtypes
     DOT core_type EQUAL seq_expr
       { let poly_exp_loc = ($startpos($7), $endpos($11)) in
         let poly_exp =
           let exp, poly =
             (* it seems odd to use the global ~loc here while poly_exp_loc
@@@@
     { let seq = mkexp ~loc:$sloc (Pexp_sequence ($1, $5)) in
       let payload = PStr [mkstrexp seq []] in
       mkexp ~loc:$sloc (Pexp_extension ($4, payload)) }
 ;
 labeled_simple_pattern:
-    QUESTION LPAREN label_let_pattern opt_default RPAREN
-      { (Optional (fst $3), $4, snd $3) }
+    QUESTION LPAREN optional_local label_let_pattern opt_default RPAREN
+      { (Optional (fst $4), $5, local_if Pattern $3 $loc($3) (snd $4)) }
   | QUESTION label_var
       { (Optional (fst $2), None, snd $2) }
-  | OPTLABEL LPAREN let_pattern opt_default RPAREN
-      { (Optional $1, $4, $3) }
+  | OPTLABEL LPAREN optional_local let_pattern opt_default RPAREN
+      { (Optional $1, $5, local_if Pattern $3 $loc($3) $4) }
   | OPTLABEL pattern_var
       { (Optional $1, None, $2) }
-  | TILDE LPAREN label_let_pattern RPAREN
-      { (Labelled (fst $3), None, snd $3) }
+  | TILDE LPAREN optional_local label_let_pattern RPAREN
+      { (Labelled (fst $4), None,
+         local_if Pattern $3 $loc($3) (snd $4)) }
   | TILDE label_var
       { (Labelled (fst $2), None, snd $2) }
   | LABEL simple_pattern
       { (Labelled $1, None, $2) }
+  | LABEL LPAREN LOCAL pattern RPAREN
+      { (Labelled $1, None,
+         Jane_syntax.Local.pat_of ~loc:(make_loc $loc($3)) ~attrs:[]
+           (Lpat_local $4) ) }
   | simple_pattern
       { (Nolabel, None, $1) }
+  | LPAREN LOCAL let_pattern RPAREN
+      { (Nolabel, None,
+         Jane_syntax.Local.pat_of ~loc:(make_loc $loc($2)) ~attrs:[]
+           (Lpat_local $3)) }
+  | LABEL LPAREN poly_pattern RPAREN
+      { (Labelled $1, None, $3) }
+  | LABEL LPAREN LOCAL poly_pattern RPAREN
+      { (Labelled $1, None,
+         Jane_syntax.Local.pat_of ~loc:(make_loc $loc($3)) ~attrs:[]
+           (Lpat_local $4)) }
+  | LPAREN poly_pattern RPAREN
+      { (Nolabel, None, $2) }
 ;
 
 pattern_var:
   mkpat(
       mkrhs(LIDENT)     { Ppat_var $1 }
@@@@
       { x }
   | x = label_var COLON cty = core_type
       { let lab, pat = x in
         lab,
         mkpat ~loc:$sloc (Ppat_constraint (pat, cty)) }
+  | x = label_var COLON
+          cty = mktyp_jane_syntax_ltyp (bound_vars = typevar_list
+                                        DOT
+                                        inner_type = core_type
+                  { Jane_syntax.Layouts.Ltyp_poly { bound_vars; inner_type } })
+      { let lab, pat = x in
+        lab,
+        mkpat ~loc:$sloc (Ppat_constraint (pat, cty)) }
 ;
 %inline label_var:
     mkrhs(LIDENT)
       { ($1.Location.txt, mkpat ~loc:$sloc (Ppat_var $1)) }
 ;
@@@@
     pattern
       { $1 }
   | mkpat(pattern COLON core_type
       { Ppat_constraint($1, $3) })
       { $1 }
+  | poly_pattern
+      { $1 }
+;
+%inline poly_pattern:
+    mkpat(
+      pat = pattern
+      COLON
+      cty = mktyp_jane_syntax_ltyp(bound_vars = typevar_list
+                                   DOT
+                                   inner_type = core_type
+              { Jane_syntax.Layouts.Ltyp_poly { bound_vars; inner_type } })
+        { Ppat_constraint(pat, cty) })
+      { $1 }
 ;
 
 %inline indexop_expr(dot, index, right):
   | array=simple_expr d=dot LPAREN i=index RPAREN r=right
     { array, d, Paren,   i, r }
@@@@
       { mkexp ~loc:$sloc (Pexp_setfield($1, $3, $5)) }
   | indexop_expr(DOT, seq_expr, LESSMINUS v=expr {Some v})
     { mk_indexop_expr builtin_indexing_operators ~loc:$sloc $1 }
   | indexop_expr(qualified_dotop, expr_semi_list, LESSMINUS v=expr {Some v})
     { mk_indexop_expr user_indexing_operators ~loc:$sloc $1 }
+  | FUN ext_attributes LPAREN TYPE newtypes RPAREN fun_def
+    { let loc = $sloc in
+      wrap_exp_attrs ~loc (mk_newtypes ~loc $5 $7) $2 }
+  | FUN ext_attributes LPAREN TYPE mkrhs(LIDENT) COLON layout_annotation RPAREN fun_def
+    { let loc = $sloc in
+      wrap_exp_attrs ~loc (mk_newtypes ~loc:$sloc [$5, Some $7] $9) $2 }
   | expr attribute
       { Exp.attr $1 $2 }
 /* BEGIN AVOID */
+  (*
   | UNDERSCORE
      { not_expecting $loc($1) "wildcard \"_\"" }
+  *)
 /* END AVOID */
+  | LOCAL seq_expr
+      { Jane_syntax.Local.expr_of ~loc:(make_loc $sloc) ~attrs:[]
+          (Lexp_local $2) }
+  | EXCLAVE seq_expr
+     { Jane_syntax.Local.expr_of ~loc:(make_loc $sloc) ~attrs:[]
+          (Lexp_exclave $2) }
 ;
 %inline expr_attrs:
   | LET MODULE ext_attributes mkrhs(module_name) module_binding_body IN seq_expr
       { Pexp_letmodule($4, $5, $7), $3 }
   | LET EXCEPTION ext_attributes let_exception_declaration IN seq_expr
@@@@
         let od = Opn.mk $5 ~override:$3 ~loc:open_loc in
         Pexp_open(od, $7), $4 }
   | FUNCTION ext_attributes match_cases
       { Pexp_function $3, $2 }
   | FUN ext_attributes labeled_simple_pattern fun_def
-      { let (l,o,p) = $3 in
-        Pexp_fun(l, o, p, $4), $2 }
-  | FUN ext_attributes LPAREN TYPE lident_list RPAREN fun_def
-      { (mk_newtypes ~loc:$sloc $5 $7).pexp_desc, $2 }
+      { let ext, attrs = $2 in
+        let (l,o,p) = $3 in
+        Pexp_fun(l, o, p, $4), (ext, attrs) }
   | MATCH ext_attributes seq_expr WITH match_cases
       { Pexp_match($3, $5), $2 }
   | TRY ext_attributes seq_expr WITH match_cases
       { Pexp_try($3, $5), $2 }
   | TRY ext_attributes seq_expr WITH error
@@@@
       { Pexp_for($3, $5, $7, $6, $8), $2 }
   | ASSERT ext_attributes simple_expr %prec below_HASH
       { Pexp_assert $3, $2 }
   | LAZY ext_attributes simple_expr %prec below_HASH
       { Pexp_lazy $3, $2 }
+  | subtractive expr %prec prec_unary_minus
+      { let desc, attrs = mkuminus ~oploc:$loc($1) $1 $2 in
+        desc, (None, attrs) }
+  | additive expr %prec prec_unary_plus
+      { let desc, attrs = mkuplus ~oploc:$loc($1) $1 $2 in
+        desc, (None, attrs) }
 ;
 %inline do_done_expr:
   | DO e = seq_expr DONE
       { e }
   | DO seq_expr error
@@@@
       { Pexp_construct($1, Some $2) }
   | name_tag simple_expr %prec below_HASH
       { Pexp_variant($1, Some $2) }
   | e1 = expr op = op(infix_operator) e2 = expr
       { mkinfix e1 op e2 }
-  | subtractive expr %prec prec_unary_minus
-      { mkuminus ~oploc:$loc($1) $1 $2 }
-  | additive expr %prec prec_unary_plus
-      { mkuplus ~oploc:$loc($1) $1 $2 }
 ;
 
 simple_expr:
   | LPAREN seq_expr RPAREN
       { reloc_exp ~loc:$sloc $2 }
@@@@
       { unclosed "(" $loc($1) ")" $loc($3) }
   | LPAREN seq_expr type_constraint RPAREN
       { mkexp_constraint ~loc:$sloc $2 $3 }
   | indexop_expr(DOT, seq_expr, { None })
       { mk_indexop_expr builtin_indexing_operators ~loc:$sloc $1 }
+  (* Immutable array indexing is a regular operator, so it doesn't need its own
+     rule and is handled by the next case *)
   | indexop_expr(qualified_dotop, expr_semi_list, { None })
       { mk_indexop_expr user_indexing_operators ~loc:$sloc $1 }
   | indexop_error (DOT, seq_expr) { $1 }
   | indexop_error (qualified_dotop, expr_semi_list) { $1 }
   | simple_expr_attrs
     { let desc, attrs = $1 in
       mkexp_attrs ~loc:$sloc desc attrs }
   | mkexp(simple_expr_)
       { $1 }
+  | constant { Constant.to_expression ~loc:$sloc $1 }
 ;
 %inline simple_expr_attrs:
   | BEGIN ext = ext attrs = attributes e = seq_expr END
       { e.pexp_desc, (ext, attrs @ e.pexp_attributes) }
   | BEGIN ext_attributes END
@@@@
   | OBJECT ext_attributes class_structure END
       { Pexp_object $3, $2 }
   | OBJECT ext_attributes class_structure error
       { unclosed "object" $loc($1) "end" $loc($4) }
 ;
+
+comprehension_iterator:
+  | EQUAL expr direction_flag expr
+      { Jane_syntax.Comprehensions.Range { start = $2 ; stop = $4 ; direction = $3 } }
+  | IN expr
+      { Jane_syntax.Comprehensions.In $2 }
+;
+
+comprehension_clause_binding:
+  | attributes pattern comprehension_iterator
+      { Jane_syntax.Comprehensions.{ pattern = $2 ; iterator = $3 ; attributes = $1 } }
+  (* We can't write [[e for local_ x = 1 to 10]], because the [local_] has to
+     move to the RHS and there's nowhere for it to move to; besides, you never
+     want that [int] to be [local_].  But we can parse [[e for local_ x in xs]].
+     We have to have that as a separate rule here because it moves the [local_]
+     over to the RHS of the binding, so we need everything to be visible. *)
+  | attributes LOCAL pattern IN expr
+      { Jane_syntax.Comprehensions.
+          { pattern    = $3
+          ; iterator   = In (Jane_syntax.Local.expr_of
+                               ~loc:(make_loc $sloc) ~attrs:[]
+                               (Lexp_local $5))
+          ; attributes = $1
+          }
+      }
+;
+
+comprehension_clause:
+  | FOR separated_nonempty_llist(AND, comprehension_clause_binding)
+      { Jane_syntax.Comprehensions.For $2 }
+  | WHEN expr
+      { Jane_syntax.Comprehensions.When $2 }
+
+%inline comprehension(lbracket, rbracket):
+  lbracket expr nonempty_llist(comprehension_clause) rbracket
+    { Jane_syntax.Comprehensions.{ body = $2; clauses = $3 } }
+;
+
+%inline comprehension_ext_expr:
+  | comprehension(LBRACKET,RBRACKET)
+      { Jane_syntax.Comprehensions.Cexp_list_comprehension  $1 }
+  | comprehension(LBRACKETBAR,BARRBRACKET)
+      { Jane_syntax.Comprehensions.Cexp_array_comprehension (Mutable, $1) }
+  | comprehension(LBRACKETCOLON,COLONRBRACKET)
+      { Jane_syntax.Comprehensions.Cexp_array_comprehension (Immutable, $1) }
+;
+
+%inline comprehension_expr:
+  comprehension_ext_expr
+    { (Jane_syntax.Comprehensions.expr_of
+         ~attrs:[] ~loc:(make_loc $sloc) $1).pexp_desc }
+;
+
+%inline array_simple(ARR_OPEN, ARR_CLOSE, contents_semi_list):
+  | ARR_OPEN contents_semi_list ARR_CLOSE
+      { Generic_array.Literal $2 }
+  | ARR_OPEN contents_semi_list error
+      { Generic_array.Unclosed($loc($1),$loc($3)) }
+  | ARR_OPEN ARR_CLOSE
+      { Generic_array.Literal [] }
+;
+
+%inline array_exprs(ARR_OPEN, ARR_CLOSE):
+  | array_simple(ARR_OPEN, ARR_CLOSE, expr_semi_list)
+      { $1 }
+  | od=open_dot_declaration DOT ARR_OPEN expr_semi_list ARR_CLOSE
+      { Generic_array.Opened_literal(od, $startpos($3), $endpos, $4) }
+  | od=open_dot_declaration DOT ARR_OPEN ARR_CLOSE
+      { (* TODO: review the location of Pexp_array *)
+        Generic_array.Opened_literal(od, $startpos($3), $endpos, []) }
+  | mod_longident DOT
+    ARR_OPEN expr_semi_list error
+      { Generic_array.Unclosed($loc($3), $loc($5)) }
+;
+
+%inline array_patterns(ARR_OPEN, ARR_CLOSE):
+  | array_simple(ARR_OPEN, ARR_CLOSE, pattern_semi_list)
+      { $1 }
+;
+
+%inline hash:
+  | HASH { () }
+  | HASH_SUFFIX { () }
+;
+
 %inline simple_expr_:
   | mkrhs(val_longident)
       { Pexp_ident ($1) }
-  | constant
-      { Pexp_constant $1 }
   | mkrhs(constr_longident) %prec prec_constant_constructor
       { Pexp_construct($1, None) }
   | name_tag %prec prec_constant_constructor
       { Pexp_variant($1, None) }
   | op(PREFIXOP) simple_expr
@@@@
   | od=open_dot_declaration DOT LBRACELESS object_expr_content GREATERRBRACE
       { (* TODO: review the location of Pexp_override *)
         Pexp_open(od, mkexp ~loc:$sloc (Pexp_override $4)) }
   | mod_longident DOT LBRACELESS object_expr_content error
       { unclosed "{<" $loc($3) ">}" $loc($5) }
-  | simple_expr HASH mkrhs(label)
+  | simple_expr hash mkrhs(label)
       { Pexp_send($1, $3) }
   | simple_expr op(HASHOP) simple_expr
       { mkinfix $1 $2 $3 }
   | extension
       { Pexp_extension $1 }
+  | UNDERSCORE
+      { Pexp_hole }
   | od=open_dot_declaration DOT mkrhs(LPAREN RPAREN {Lident "()"})
       { Pexp_open(od, mkexp ~loc:($loc($3)) (Pexp_construct($3, None))) }
   | mod_longident DOT LPAREN seq_expr error
       { unclosed "(" $loc($3) ")" $loc($5) }
   | LBRACE record_expr_content RBRACE
@@@@
       { let (exten, fields) = $4 in
         Pexp_open(od, mkexp ~loc:($startpos($3), $endpos)
                         (Pexp_record(fields, exten))) }
   | mod_longident DOT LBRACE record_expr_content error
       { unclosed "{" $loc($3) "}" $loc($5) }
-  | LBRACKETBAR expr_semi_list BARRBRACKET
-      { Pexp_array($2) }
-  | LBRACKETBAR expr_semi_list error
-      { unclosed "[|" $loc($1) "|]" $loc($3) }
-  | LBRACKETBAR BARRBRACKET
-      { Pexp_array [] }
-  | od=open_dot_declaration DOT LBRACKETBAR expr_semi_list BARRBRACKET
-      { Pexp_open(od, mkexp ~loc:($startpos($3), $endpos) (Pexp_array($4))) }
-  | od=open_dot_declaration DOT LBRACKETBAR BARRBRACKET
-      { (* TODO: review the location of Pexp_array *)
-        Pexp_open(od, mkexp ~loc:($startpos($3), $endpos) (Pexp_array [])) }
-  | mod_longident DOT
-    LBRACKETBAR expr_semi_list error
-      { unclosed "[|" $loc($3) "|]" $loc($5) }
+  | array_exprs(LBRACKETBAR, BARRBRACKET)
+      { Generic_array.expression
+          "[|" "|]"
+          (fun elts -> Pexp_array elts)
+          $1 }
+  | array_exprs(LBRACKETCOLON, COLONRBRACKET)
+      { Generic_array.expression
+          "[:" ":]"
+          (fun elts ->
+            (Jane_syntax.Immutable_arrays.expr_of
+               ~attrs:[]
+               ~loc:(make_loc $sloc)
+               (Iaexp_immutable_array elts)).pexp_desc)
+          $1 }
   | LBRACKET expr_semi_list RBRACKET
       { fst (mktailexp $loc($3) $2) }
   | LBRACKET expr_semi_list error
       { unclosed "[" $loc($1) "]" $loc($3) }
+  | comprehension_expr { $1 }
+  | od=open_dot_declaration DOT comprehension_expr
+      { Pexp_open(od, mkexp ~loc:($loc($3)) $3) }
   | od=open_dot_declaration DOT LBRACKET expr_semi_list RBRACKET
       { let list_exp =
           (* TODO: review the location of list_exp *)
           let tail_exp, _tail_loc = mktailexp $loc($5) $4 in
           mkexp ~loc:($startpos($3), $endpos) tail_exp in
@@@@
     val_ident { mkpatvar ~loc:$sloc $1 }
 ;
 let_binding_body_no_punning:
     let_ident strict_binding
       { ($1, $2) }
-  | let_ident type_constraint EQUAL seq_expr
-      { let v = $1 in (* PR#7344 *)
+  | optional_local let_ident type_constraint EQUAL seq_expr
+      { let v = $2 in (* PR#7344 *)
         let t =
-          match $2 with
+          match $3 with
             Some t, None -> t
           | _, Some t -> t
           | _ -> assert false
         in
         let loc = Location.(t.ptyp_loc.loc_start, t.ptyp_loc.loc_end) in
+        let local_loc = $loc($1) in
         let typ = ghtyp ~loc (Ptyp_poly([],t)) in
-        let patloc = ($startpos($1), $endpos($2)) in
-        (ghpat ~loc:patloc (Ppat_constraint(v, typ)),
-         mkexp_constraint ~loc:$sloc $4 $2) }
-  | let_ident COLON poly(core_type) EQUAL seq_expr
-      { let patloc = ($startpos($1), $endpos($3)) in
-        (ghpat ~loc:patloc
-           (Ppat_constraint($1, ghtyp ~loc:($loc($3)) $3)),
-         $5) }
-  | let_ident COLON TYPE lident_list DOT core_type EQUAL seq_expr
+        let patloc = ($startpos($2), $endpos($3)) in
+        let pat =
+          local_if Pattern $1 local_loc
+            (ghpat ~loc:patloc (Ppat_constraint(v, typ)))
+        in
+        let exp =
+          local_if Expression $1 $sloc
+            (mkexp_constraint
+              ~loc:$sloc
+              (local_if Synthesized_constraint $1 $sloc $5)
+              $3)
+        in
+        (pat, exp) }
+  | optional_local let_ident COLON poly(core_type) EQUAL seq_expr
+      { let patloc = ($startpos($2), $endpos($4)) in
+        let bound_vars, inner_type = $4 in
+        let ltyp = Jane_syntax.Layouts.Ltyp_poly { bound_vars; inner_type } in
+        let typ_loc = Location.ghostify (make_loc $loc($4)) in
+        let typ =
+          Jane_syntax.Layouts.type_of ~loc:typ_loc ~attrs:[] ltyp
+        in
+        let pat =
+          local_if Pattern $1 $loc($1)
+            (ghpat ~loc:patloc
+               (Ppat_constraint($2, typ)))
+        in
+        let exp = local_if Expression $1 $sloc $6 in
+        (pat, exp) }
+  | let_ident COLON TYPE newtypes DOT core_type EQUAL seq_expr
       { let exp, poly =
           wrap_type_annotation ~loc:$sloc $4 $6 $8 in
         let loc = ($startpos($1), $endpos($6)) in
         (ghpat ~loc (Ppat_constraint($1, poly)), exp) }
   | pattern_no_exn EQUAL seq_expr
       { ($1, $3) }
   | simple_pattern_not_ident COLON core_type EQUAL seq_expr
       { let loc = ($startpos($1), $endpos($3)) in
         (ghpat ~loc (Ppat_constraint($1, $3)), $5) }
+  | LOCAL let_ident local_strict_binding
+      { ($2, Jane_syntax.Local.expr_of ~loc:(make_loc $sloc) ~attrs:[]
+               (Lexp_local $3)) }
 ;
 let_binding_body:
   | let_binding_body_no_punning
       { let p,e = $1 in (p,e,false) }
 /* BEGIN AVOID */
@@@@
 strict_binding:
     EQUAL seq_expr
       { $2 }
   | labeled_simple_pattern fun_binding
       { let (l, o, p) = $1 in ghexp ~loc:$sloc (Pexp_fun(l, o, p, $2)) }
-  | LPAREN TYPE lident_list RPAREN fun_binding
+  | LPAREN TYPE newtypes RPAREN fun_binding
       { mk_newtypes ~loc:$sloc $3 $5 }
+  | LPAREN TYPE mkrhs(LIDENT) COLON layout_annotation RPAREN fun_binding
+      { mk_newtypes ~loc:$sloc [$3, Some $5] $7 }
+;
+local_fun_binding:
+    local_strict_binding
+      { $1 }
+  | type_constraint EQUAL seq_expr
+      { mkexp_constraint
+          ~loc:$sloc
+          (Jane_syntax.Local.expr_of ~loc:(make_loc $sloc) ~attrs:[]
+             (Lexp_constrain_local $3))
+          $1 }
+;
+local_strict_binding:
+    EQUAL seq_expr
+      { $2 }
+  | labeled_simple_pattern local_fun_binding
+      { let (l, o, p) = $1 in ghexp ~loc:$sloc (Pexp_fun(l, o, p, $2)) }
+  | LPAREN TYPE newtypes RPAREN local_fun_binding
+      { mk_newtypes ~loc:$sloc $3 $5 }
+  | LPAREN TYPE mkrhs(LIDENT) COLON layout_annotation RPAREN fun_binding
+      { mk_newtypes ~loc:$sloc [$3, Some $5] $7 }
 ;
 %inline match_cases:
   xs = preceded_or_separated_nonempty_llist(BAR, match_case)
     { xs }
 ;
@@@@
   | labeled_simple_pattern fun_def
       {
        let (l,o,p) = $1 in
        ghexp ~loc:$sloc (Pexp_fun(l, o, p, $2))
       }
-  | LPAREN TYPE lident_list RPAREN fun_def
+  | LPAREN TYPE newtypes RPAREN fun_def
       { mk_newtypes ~loc:$sloc $3 $5 }
+  | LPAREN TYPE mkrhs(LIDENT) COLON layout_annotation RPAREN fun_def
+      { mk_newtypes ~loc:$sloc [$3, Some $5] $7 }
 ;
 %inline expr_comma_list:
   es = separated_nontrivial_llist(COMMA, expr)
     { es }
 ;
@@@@
   | COLONGREATER core_type                      { (None, Some $2) }
   | COLON error                                 { syntax_error() }
   | COLONGREATER error                          { syntax_error() }
 ;
 
+(* the thing between the [type] and the [.] in
+   [let : type <<here>>. 'a -> 'a = ...] *)
+newtypes: (* : (string with_loc * layout_annotation option) list *)
+  newtype+
+    { $1 }
+
+newtype: (* : string with_loc * layout_annotation option *)
+    mkrhs(LIDENT)                     { $1, None }
+  | LPAREN name=mkrhs(LIDENT) COLON layout=layout_annotation RPAREN
+      { name, Some layout }
+
 /* Patterns */
 
 (* Whereas [pattern] is an arbitrary pattern, [pattern_no_exn] is a pattern
    that does not begin with the [EXCEPTION] keyword. Thus, [pattern_no_exn]
    is the intersection of the context-free language [pattern] with the
@@@@
       { mkpat_attrs ~loc:$sloc
           (Ppat_constraint(mkpat ~loc:$loc($4) (Ppat_unpack $4), $6))
           $3 }
   | mkpat(simple_pattern_not_ident_)
       { $1 }
+  | signed_constant { Constant.to_pattern $1 ~loc:$sloc }
 ;
 %inline simple_pattern_not_ident_:
   | UNDERSCORE
       { Ppat_any }
-  | signed_constant
-      { Ppat_constant $1 }
   | signed_constant DOTDOT signed_constant
-      { Ppat_interval ($1, $3) }
+      { let where = "in a pattern interval" in
+        Ppat_interval
+          (Constant.assert_is_value $1 ~loc:$loc($1) ~where,
+           Constant.assert_is_value $3 ~loc:$loc($3) ~where) }
   | mkrhs(constr_longident)
       { Ppat_construct($1, None) }
   | name_tag
       { Ppat_variant($1, None) }
-  | HASH mkrhs(type_longident)
+  | hash mkrhs(type_longident)
       { Ppat_type ($2) }
   | mkrhs(mod_longident) DOT simple_delimited_pattern
       { Ppat_open($1, $3) }
   | mkrhs(mod_longident) DOT mkrhs(LBRACKET RBRACKET {Lident "[]"})
     { Ppat_open($1, mkpat ~loc:$sloc (Ppat_construct($3, None))) }
@@@@
       { unclosed "{" $loc($1) "}" $loc($3) }
     | LBRACKET pattern_semi_list RBRACKET
       { fst (mktailpat $loc($3) $2) }
     | LBRACKET pattern_semi_list error
       { unclosed "[" $loc($1) "]" $loc($3) }
-    | LBRACKETBAR pattern_semi_list BARRBRACKET
-      { Ppat_array $2 }
-    | LBRACKETBAR BARRBRACKET
-      { Ppat_array [] }
-    | LBRACKETBAR pattern_semi_list error
-      { unclosed "[|" $loc($1) "|]" $loc($3) }
+    | array_patterns(LBRACKETBAR, BARRBRACKET)
+        { Generic_array.pattern
+            "[|" "|]"
+            (fun elts -> Ppat_array elts)
+            $1 }
+    | array_patterns(LBRACKETCOLON, COLONRBRACKET)
+        { Generic_array.pattern
+            "[:" ":]"
+            (ppat_iarray $sloc)
+            $1 }
   ) { $1 }
 
 pattern_comma_list(self):
     pattern_comma_list(self) COMMA pattern      { $3 :: $1 }
   | self COMMA pattern                          { [$3; $1] }
@@@@
   ext = ext
   attrs1 = attributes
   flag = flag
   params = type_parameters
   id = mkrhs(LIDENT)
+  layout = layout_attr?
   kind_priv_manifest = kind
   cstrs = constraints
   attrs2 = post_item_attributes
     {
       let (kind, priv, manifest) = kind_priv_manifest in
       let docs = symbol_docs $sloc in
       let attrs = attrs1 @ attrs2 in
       let loc = make_loc $sloc in
       (flag, ext),
-      Type.mk id ~params ~cstrs ~kind ~priv ?manifest ~attrs ~loc ~docs
+      Type.mk id ~params ?layout ~cstrs ~kind ~priv ?manifest ~attrs ~loc ~docs
     }
 ;
 %inline generic_and_type_declaration(kind):
   AND
   attrs1 = attributes
   params = type_parameters
   id = mkrhs(LIDENT)
+  layout = layout_attr?
   kind_priv_manifest = kind
   cstrs = constraints
   attrs2 = post_item_attributes
     {
       let (kind, priv, manifest) = kind_priv_manifest in
       let docs = symbol_docs $sloc in
       let attrs = attrs1 @ attrs2 in
       let loc = make_loc $sloc in
       let text = symbol_text $symbolstartpos in
-      Type.mk id ~params ~cstrs ~kind ~priv ?manifest ~attrs ~loc ~docs ~text
+      Type.mk id ~params ?layout ~cstrs ~kind ~priv ?manifest ~attrs ~loc ~docs ~text
     }
 ;
 %inline constraints:
   llist(preceded(CONSTRAINT, constrain))
     { $1 }
@@@@
 type_parameters:
     /* empty */
       { [] }
   | p = type_parameter
       { [p] }
-  | LPAREN ps = separated_nonempty_llist(COMMA, type_parameter) RPAREN
+  | LPAREN
+    ps = separated_nonempty_llist(COMMA, parenthesized_type_parameter)
+    RPAREN
       { ps }
 ;
+
+layout_annotation: (* : layout_annotation *)
+  ident { let loc = make_loc $sloc in
+          mkloc (check_layout ~loc $1) loc }
+;
+
+layout_string: (* : string with_loc *)
+  (* the [check_layout] just ensures this is the name of a layout *)
+  ident { let loc = make_loc $sloc in
+          ignore (check_layout ~loc $1 : const_layout);
+          mkloc $1 loc }
+;
+
+layout_attr:
+  COLON
+  layout=layout_string
+    { Attr.mk ~loc:layout.loc layout (PStr []) }
+;
+
+%inline type_param_with_layout:
+  name=tyvar_name_or_underscore
+  attrs=attributes
+  COLON
+  layout=layout_annotation
+    { Jane_syntax.Layouts.type_of ~loc:(make_loc $sloc) ~attrs
+        (Ltyp_var { name; layout }) }
+;
+
+parenthesized_type_parameter:
+    type_parameter { $1 }
+  | type_variance type_param_with_layout
+    { $2, $1 }
+;
+
 type_parameter:
-    type_variance type_variable        { $2, $1 }
+    type_variance type_variable attributes
+      { {$2 with ptyp_attributes = $3}, $1 }
 ;
-type_variable:
+
+%inline type_variable:
   mktyp(
     QUOTE tyvar = ident
       { Ptyp_var tyvar }
   | UNDERSCORE
       { Ptyp_any }
   ) { $1 }
 ;
 
+%inline tyvar_name_or_underscore:
+    QUOTE ident
+      { Some $2 }
+  | UNDERSCORE
+      { None }
+;
+
 type_variance:
     /* empty */                             { NoVariance, NoInjectivity }
   | PLUS                                    { Covariant, NoInjectivity }
   | MINUS                                   { Contravariant, NoInjectivity }
   | BANG                                    { NoVariance, Injective }
@@@@
     }
 ;
 %inline constructor_declaration(opening):
   d = generic_constructor_declaration(opening)
     {
-      let cid, vars, args, res, attrs, loc, info = d in
-      Type.constructor cid ~vars ~args ?res ~attrs ~loc ~info
+      let cid, vars_layouts, args, res, attrs, loc, info = d in
+      Jane_syntax.Layouts.constructor_declaration_of
+        cid ~vars_layouts ~args ~res ~attrs ~loc ~info
     }
 ;
 str_exception_declaration:
   sig_exception_declaration
     { $1 }
@@@@
   attrs1 = attributes
   id = mkrhs(constr_ident)
   vars_args_res = generalized_constructor_arguments
   attrs2 = attributes
   attrs = post_item_attributes
-    { let vars, args, res = vars_args_res in
+    { let vars_layouts, args, res = vars_args_res in
       let loc = make_loc ($startpos, $endpos(attrs2)) in
       let docs = symbol_docs $sloc in
-      Te.mk_exception ~attrs
-        (Te.decl id ~vars ~args ?res ~attrs:(attrs1 @ attrs2) ~loc ~docs)
-      , ext }
+      let ext_ctor =
+        Jane_syntax.Layouts.extension_constructor_of
+          ~loc ~name:id ~attrs:(attrs1 @ attrs2) ~docs
+          (Lext_decl (vars_layouts, args, res))
+      in
+      Te.mk_exception ~attrs ext_ctor, ext }
 ;
 %inline let_exception_declaration:
     mkrhs(constr_ident) generalized_constructor_arguments attributes
-      { let vars, args, res = $2 in
-        Te.decl $1 ~vars ~args ?res ~attrs:$3 ~loc:(make_loc $sloc) }
+      { let vars_layouts, args, res = $2 in
+        Jane_syntax.Layouts.extension_constructor_of
+            ~loc:(make_loc $sloc)
+            ~name:$1
+            ~attrs:$3
+            (Lext_decl (vars_layouts, args, res)) }
 ;
+
 generalized_constructor_arguments:
     /*empty*/                     { ([],Pcstr_tuple [],None) }
   | OF constructor_arguments      { ([],$2,None) }
   | COLON constructor_arguments MINUSGREATER atomic_type %prec below_HASH
                                   { ([],$2,Some $4) }
@@@@
                                   { ([],Pcstr_tuple [],Some $2) }
   | COLON typevar_list DOT atomic_type %prec below_HASH
                                   { ($2,Pcstr_tuple [],Some $4) }
 ;
 
+%inline atomic_type_gbl:
+  gbl = global_flag cty = atomic_type {
+  global_if gbl $loc(gbl) cty
+}
+;
+
 constructor_arguments:
-  | tys = inline_separated_nonempty_llist(STAR, atomic_type)
+  | tys = inline_separated_nonempty_llist(STAR, atomic_type_gbl)
     %prec below_HASH
       { Pcstr_tuple tys }
   | LBRACE label_declarations RBRACE
       { Pcstr_record $2 }
 ;
@@@@
     label_declaration                           { [$1] }
   | label_declaration_semi                      { [$1] }
   | label_declaration_semi label_declarations   { $1 :: $2 }
 ;
 label_declaration:
-    mutable_flag mkrhs(label) COLON poly_type_no_attr attributes
+    mutable_or_global_flag mkrhs(label) COLON poly_type_no_attr attributes
       { let info = symbol_info $endpos in
-        Type.field $2 $4 ~mut:$1 ~attrs:$5 ~loc:(make_loc $sloc) ~info }
+        let mut, gbl = $1 in
+        Type.field
+          $2
+          (global_if gbl $loc($1) $4)
+          ~mut
+          ~attrs:$5
+          ~loc:(make_loc $sloc)
+          ~info }
 ;
 label_declaration_semi:
-    mutable_flag mkrhs(label) COLON poly_type_no_attr attributes SEMI attributes
+    mutable_or_global_flag mkrhs(label) COLON poly_type_no_attr attributes
+      SEMI attributes
       { let info =
           match rhs_info $endpos($5) with
           | Some _ as info_before_semi -> info_before_semi
           | None -> symbol_info $endpos
        in
-       Type.field $2 $4 ~mut:$1 ~attrs:($5 @ $7) ~loc:(make_loc $sloc) ~info }
+       let mut, gbl = $1 in
+       Type.field
+         $2
+         (global_if gbl $loc($1) $4)
+         ~mut
+         ~attrs:($5 @ $7)
+         ~loc:(make_loc $sloc)
+         ~info }
 ;
 
 /* Type Extensions */
 
 %inline str_type_extension:
@@@@
       { $1 }
 ;
 %inline extension_constructor_declaration(opening):
   d = generic_constructor_declaration(opening)
     {
-      let cid, vars, args, res, attrs, loc, info = d in
-      Te.decl cid ~vars ~args ?res ~attrs ~loc ~info
+      let name, vars_layouts, args, res, attrs, loc, info = d in
+      Jane_syntax.Layouts.extension_constructor_of
+        ~loc ~attrs ~info ~name (Lext_decl(vars_layouts, args, res))
     }
 ;
 extension_constructor_rebind(opening):
   opening
   cid = mkrhs(constr_ident)
@@@@
   | EQUAL PRIVATE  { Private }
 ;
 
 /* Polymorphic types */
 
-%inline typevar:
-  QUOTE mkrhs(ident)
-    { $2 }
+%inline typevar: (* : string with_loc * layout_annotation option *)
+    QUOTE mkrhs(ident)
+      { ($2, None) }
+    | LPAREN QUOTE tyvar=mkrhs(ident) COLON layout=layout_annotation RPAREN
+      { (tyvar, Some layout) }
 ;
 %inline typevar_list:
+  (* : (string with_loc * layout_annotation option) list *)
   nonempty_llist(typevar)
     { $1 }
 ;
 %inline poly(X):
   typevar_list DOT X
-    { Ptyp_poly($1, $3) }
+    { ($1, $3) }
 ;
 possibly_poly(X):
   X
     { $1 }
-| mktyp(poly(X))
-    { $1 }
+| poly(X)
+    { let bound_vars, inner_type = $1 in
+      Jane_syntax.Layouts.type_of ~loc:(make_loc $sloc) ~attrs:[]
+        (Ltyp_poly { bound_vars; inner_type }) }
 ;
 %inline poly_type:
   possibly_poly(core_type)
     { $1 }
 ;
@@@@
     function_type
       { $1 }
   | mktyp(
       ty = alias_type AS QUOTE tyvar = ident
         { Ptyp_alias(ty, tyvar) }
-    )
-    { $1 }
+   )
+   { $1 }
+  | aliased_type = alias_type AS
+             LPAREN
+             name = tyvar_name_or_underscore
+             COLON
+             layout = layout_annotation
+             RPAREN
+        { Jane_syntax.Layouts.type_of ~loc:(make_loc $sloc) ~attrs:[]
+              (Ltyp_alias { aliased_type; name; layout }) }
 ;
 
 (* Function types include:
    - tuple types (see below);
    - proper function types:               int -> int
@@@@
  *)
 function_type:
   | ty = tuple_type
     %prec MINUSGREATER
       { ty }
+  | ty = strict_function_type
+      { ty }
+;
+
+strict_function_type:
   | mktyp(
       label = arg_label
-      domain = extra_rhs(tuple_type)
+      local = optional_local
+      domain = extra_rhs(param_type)
       MINUSGREATER
-      codomain = function_type
-        { Ptyp_arrow(label, domain, codomain) }
+      codomain = strict_function_type
+        { Ptyp_arrow(label, local_if Type local $loc(local) domain, codomain) }
+    )
+    { $1 }
+  | mktyp(
+      label = arg_label
+      arg_local = optional_local
+      domain = extra_rhs(param_type)
+      MINUSGREATER
+      ret_local = optional_local
+      codomain = tuple_type
+      %prec MINUSGREATER
+        { Ptyp_arrow(label,
+            local_if Type arg_local $loc(arg_local) domain,
+            local_if Type ret_local $loc(ret_local)
+              (Jane_syntax.Builtin.mark_curried
+                 ~loc:(make_loc $loc(codomain)) codomain)) }
+    )
+    { $1 }
+;
+%inline param_type:
+  | mktyp_jane_syntax_ltyp(
+    LPAREN bound_vars = typevar_list DOT inner_type = core_type RPAREN
+      { Jane_syntax.Layouts.Ltyp_poly { bound_vars; inner_type } }
     )
     { $1 }
+  | ty = tuple_type
+    { ty }
 ;
 %inline arg_label:
   | label = optlabel
       { Optional label }
   | label = LIDENT COLON
       { Labelled label }
   | /* empty */
       { Nolabel }
 ;
+%inline optional_local:
+  | /* empty */
+    { false }
+  | LOCAL
+    { true }
+;
 (* Tuple types include:
    - atomic types (see below);
    - proper tuple types:                  int * int * int list
    A proper tuple type is a star-separated list of at least two atomic types.
  *)
@@@@
         { Ptyp_var $2 }
     | UNDERSCORE
         { Ptyp_any }
     | tys = actual_type_parameters
       tid = mkrhs(type_longident)
-        { Ptyp_constr(tid, tys) }
+      HASH_SUFFIX
+        { match tid.txt with
+          | Lident "float" ->
+              let ident_start = fst $loc(tid) in
+              let hash_end = snd $loc($3) in
+              unboxed_float_type (ident_start, hash_end) tys
+          | _ ->
+              not_expecting $sloc "Unboxed type other than float#"
+        }
+    | tys = actual_type_parameters
+      tid = mkrhs(type_longident)
+        { Ptyp_constr(tid, tys) } %prec below_HASH
     | LESS meth_list GREATER
         { let (f, c) = $2 in Ptyp_object (f, c) }
     | LESS GREATER
         { Ptyp_object ([], Closed) }
     | tys = actual_type_parameters
@@@@
         { Ptyp_variant($3, Closed, Some $5) }
     | extension
         { Ptyp_extension $1 }
   )
   { $1 } /* end mktyp group */
-;
+  | LPAREN QUOTE name=ident COLON layout=layout_annotation RPAREN
+      { Jane_syntax.Layouts.type_of ~loc:(make_loc $sloc) ~attrs:[] @@
+        Ltyp_var { name = Some name; layout } }
+  | LPAREN UNDERSCORE COLON layout=layout_annotation RPAREN
+      { Jane_syntax.Layouts.type_of ~loc:(make_loc $sloc) ~attrs:[] @@
+        Ltyp_var { name = None; layout } }
+
 
 (* This is the syntax of the actual type parameters in an application of
    a type constructor, such as int, int list, or (int, bool) Hashtbl.t.
    We allow one of the following:
    - zero parameters;
@@@@
       { [] }
   | ty = atomic_type
       { [ty] }
   | LPAREN tys = separated_nontrivial_llist(COMMA, core_type) RPAREN
       { tys }
-;
 
 %inline package_type: module_type
       { let (lid, cstrs, attrs) = package_type_of_module_type $1 in
         let descr = Ptyp_package (lid, cstrs) in
         mktyp ~loc:$sloc ~attrs descr }
@@@@
 ;
 
 /* Constants */
 
 constant:
-  | INT          { let (n, m) = $1 in Pconst_integer (n, m) }
-  | CHAR         { Pconst_char $1 }
-  | STRING       { let (s, strloc, d) = $1 in Pconst_string (s, strloc, d) }
-  | FLOAT        { let (f, m) = $1 in Pconst_float (f, m) }
+  | INT               { let (n, m) = $1 in
+                        Constant.value (Pconst_integer (n, m)) }
+  | CHAR              { Constant.value (Pconst_char $1) }
+  | STRING            { let (s, strloc, d) = $1 in
+                        Constant.value (Pconst_string (s, strloc, d)) }
+  | FLOAT             { let (f, m) = $1 in
+                        Constant.value (Pconst_float (f, m)) }
+  | HASH_INT          { unboxed_int $sloc $sloc Positive $1 }
+  | HASH_FLOAT        { unboxed_float $sloc Positive $1 }
 ;
 signed_constant:
-    constant     { $1 }
-  | MINUS INT    { let (n, m) = $2 in Pconst_integer("-" ^ n, m) }
-  | MINUS FLOAT  { let (f, m) = $2 in Pconst_float("-" ^ f, m) }
-  | PLUS INT     { let (n, m) = $2 in Pconst_integer (n, m) }
-  | PLUS FLOAT   { let (f, m) = $2 in Pconst_float(f, m) }
+    constant          { $1 }
+  | MINUS INT         { let (n, m) = $2 in
+                        Constant.value (Pconst_integer("-" ^ n, m)) }
+  | MINUS FLOAT       { let (f, m) = $2 in
+                        Constant.value (Pconst_float("-" ^ f, m)) }
+  | MINUS HASH_INT    { unboxed_int $sloc $loc($2) Negative $2 }
+  | MINUS HASH_FLOAT  { unboxed_float $sloc Negative $2 }
+  | PLUS INT          { let (n, m) = $2 in
+                        Constant.value (Pconst_integer (n, m)) }
+  | PLUS FLOAT        { let (f, m) = $2 in
+                        Constant.value (Pconst_float(f, m)) }
+  | PLUS HASH_INT     { unboxed_int $sloc $loc($2) Positive $2 }
+  | PLUS HASH_FLOAT   { unboxed_float $sloc Positive $2 }
 ;
 
 /* Identifiers and long identifiers */
 
 ident:
@@@@
   | PLUS           {"+"}
   | PLUSDOT       {"+."}
   | PLUSEQ        {"+="}
   | MINUS          {"-"}
   | MINUSDOT      {"-."}
+  | SLASH          {"/"}
   | STAR           {"*"}
   | PERCENT        {"%"}
   | EQUAL          {"="}
   | LESS           {"<"}
   | GREATER        {">"}
@@@@
 label_longident:
     mk_longident(mod_longident, LIDENT) { $1 }
 ;
 type_longident:
     mk_longident(mod_ext_longident, LIDENT)  { $1 }
+  | LIDENT SLASH TYPE_DISAMBIGUATOR          { Lident ($1 ^ "/" ^ $3) }
 ;
+
 mod_longident:
     mk_longident(mod_longident, UIDENT)  { $1 }
 ;
+mod_ext_longident_:
+    UIDENT                          { Lident $1 }
+  | UIDENT SLASH TYPE_DISAMBIGUATOR { Lident ($1 ^ "/" ^ $3) }
+  | mod_ext_longident DOT UIDENT    { Ldot($1,$3) }
+;
 mod_ext_longident:
-    mk_longident(mod_ext_longident, UIDENT) { $1 }
+    mod_ext_longident_ { $1 }
   | mod_ext_longident LPAREN mod_ext_longident RPAREN
       { lapply ~loc:$sloc $1 $3 }
   | mod_ext_longident LPAREN error
       { expecting $loc($3) "module path" }
 ;
@@@@
 /* END AVOID */
 
 /* Toplevel directives */
 
 toplevel_directive:
-  HASH dir = mkrhs(ident)
+  hash dir = mkrhs(ident)
   arg = ioption(mk_directive_arg(toplevel_directive_argument))
     { mk_directive ~loc:$sloc dir arg }
 ;
 
 %inline toplevel_directive_argument:
@@@@
 ;
 mutable_flag:
     /* empty */                                 { Immutable }
   | MUTABLE                                     { Mutable }
 ;
+mutable_or_global_flag:
+    /* empty */                                 { Immutable, Nothing }
+  | MUTABLE                                     { Mutable, Nothing }
+  | GLOBAL                                      { Immutable, Global }
+;
+%inline global_flag:
+          { Nothing }
+  | GLOBAL { Global }
+;
 virtual_flag:
     /* empty */                                 { Concrete }
   | VIRTUAL                                     { Virtual }
 ;
 mutable_virtual_flags:
@@@@
   | INCLUDE { "include" }
   | INHERIT { "inherit" }
   | INITIALIZER { "initializer" }
   | LAZY { "lazy" }
   | LET { "let" }
+  | LOCAL { "local_" }
   | MATCH { "match" }
   | METHOD { "method" }
   | MODULE { "module" }
   | MUTABLE { "mutable" }
   | NEW { "new" }
--- parser-upstream/parsetree.mli
+++ parser-standard/parsetree.mli
@@@@
   | Pexp_letop of letop
       (** - [let* P = E0 in E1]
             - [let* P0 = E00 and* P1 = E01 in E1] *)
   | Pexp_extension of extension  (** [[%id]] *)
   | Pexp_unreachable  (** [.] *)
+  | Pexp_hole  (** [_] *)
 
 and case =
     {
      pc_lhs: pattern;
      pc_guard: expression option;
@@@@
       (** [functor(X : MT1) -> ME] *)
   | Pmod_apply of module_expr * module_expr  (** [ME1(ME2)] *)
   | Pmod_constraint of module_expr * module_type  (** [(ME : MT)] *)
   | Pmod_unpack of expression  (** [(val E)] *)
   | Pmod_extension of extension  (** [[%id]] *)
+  | Pmod_hole  (** [_] *)
 
 and structure = structure_item list
 
 and structure_item =
     {
--- parser-upstream/printast.ml
+++ parser-standard/printast.ml
@@@@
 open Format
 open Lexing
 open Location
 open Parsetree
 
+let const_layout_to_string = function
+  | Any -> "any"
+  | Value -> "value"
+  | Immediate -> "immediate"
+  | Immediate64 -> "immediate64"
+  | Void -> "void"
+  | Float64 -> "float64"
+
 let fmt_position with_name f l =
   let fname = if with_name then l.pos_fname else "" in
   if l.pos_lnum = -1
   then fprintf f "%s[%d]" fname l.pos_cnum
   else fprintf f "%s[%d,%d+%d]" fname l.pos_lnum l.pos_bol
@@@@
 let arg_label i ppf = function
   | Nolabel -> line i ppf "Nolabel\n"
   | Optional s -> line i ppf "Optional \"%s\"\n" s
   | Labelled s -> line i ppf "Labelled \"%s\"\n" s
 
+let tyvar ppf s =
+  if String.length s >= 2 && s.[1] = '\'' then
+    (* without the space, this would be parsed as
+       a character literal *)
+    Format.fprintf ppf "' %s" s
+  else
+    Format.fprintf ppf "'%s" s
+
+let const_layout ppf lay =
+  Format.fprintf ppf "%s" (const_layout_to_string lay)
+
+let layout_annotation i ppf layout =
+  line i ppf "%a" const_layout layout.txt
+
 let typevars ppf vs =
-  List.iter (fun x -> fprintf ppf " %a" Pprintast.tyvar x.txt) vs
+  List.iter (fun x -> fprintf ppf " %a" tyvar x.txt) vs
 
 let rec core_type i ppf x =
   line i ppf "core_type %a\n" fmt_location x.ptyp_loc;
   attributes i ppf x.ptyp_attributes;
   let i = i+1 in
@@@@
   | Pexp_extension (s, arg) ->
       line i ppf "Pexp_extension \"%s\"\n" s.txt;
       payload i ppf arg
   | Pexp_unreachable ->
       line i ppf "Pexp_unreachable"
+  | Pexp_hole ->
+      line i ppf "Pexp_hole"
 
 and value_description i ppf x =
   line i ppf "value_description %a %a\n" fmt_string_loc
        x.pval_name fmt_location x.pval_loc;
   attributes i ppf x.pval_attributes;
@@@@
       line i ppf "Pmod_unpack\n";
       expression i ppf e;
   | Pmod_extension (s, arg) ->
       line i ppf "Pmod_extension \"%s\"\n" s.txt;
       payload i ppf arg
+  | Pmod_hole ->
+      line i ppf "Pmod_hole"
 
 and structure i ppf x = list i structure_item ppf x
 
 and structure_item i ppf x =
   line i ppf "structure_item %a\n" fmt_location x.pstr_loc;
@@@@
 let interface ppf x = list 0 signature_item ppf x
 
 let implementation ppf x = list 0 structure_item ppf x
 
 let top_phrase ppf x = toplevel_phrase 0 ppf x
+
+let constant = fmt_constant
--- parser-upstream/printast.mli
+++ parser-standard/printast.mli
@@@@
 open Format
 
 val interface : formatter -> signature_item list -> unit
 val implementation : formatter -> structure_item list -> unit
 val top_phrase : formatter -> toplevel_phrase -> unit
+val constant: formatter -> constant -> unit
 
 val expression: int -> formatter -> expression -> unit
+val pattern: int -> formatter -> pattern -> unit
 val structure: int -> formatter -> structure -> unit
 val payload: int -> formatter -> payload -> unit
+val core_type: int -> formatter -> core_type -> unit
+val module_type: int -> formatter -> module_type -> unit
+val extension_constructor: int -> formatter -> extension_constructor -> unit
+
+val layout_annotation: int -> formatter -> Asttypes.layout_annotation -> unit
+val const_layout_to_string: Asttypes.const_layout -> string
+
+val tyvar: Format.formatter -> string -> unit
+  (** Print a type variable name, taking care of the special treatment
+      required for the single quote character in second position. *)
