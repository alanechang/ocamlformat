--- parser-extended/lexer.mll
+++ parser-recovery/lib/lexer.mll
@@@@
 let in_comment () = !comment_start_loc <> []
 let is_in_string = ref false
 let in_string () = !is_in_string
 let print_warnings = ref true
 
-(* Jane Street extension *)
-let at_beginning_of_line pos = (pos.pos_cnum = pos.pos_bol)
-
-(* See the comment on the [directive] lexer. *)
-type directive_lexing_already_consumed =
-   | Hash
-   | Hash_and_line_num of { line_num : string }
-
-type deferred_token =
-  { token : token
-  ; start_pos : Lexing.position
-  ; end_pos : Lexing.position
-  }
-
-(* This queue will only ever have 0 or 1 elements in it. We use it
-   instead of an [option ref] for its convenient interface.
-*)
-let deferred_tokens : deferred_token Queue.t = Queue.create ()
-
-(* Effectively splits the text in the lexer's current "window" (defined below)
-   into two halves. The current call to the lexer will return the first half of
-   the text in the window, and the next call to the lexer will return the second
-   half (of length [len]) of the text in the window.
-
-   "window" refers to the text matched by a production of the lexer. It spans
-   from [lexer.lex_start_p] to [lexer.lex_curr_p].
-
-   The function accomplishes this splitting by doing two things:
-    - It sets the current window of the lexbuf to only account for the
-      first half of the text. (The first half is of length: |text|-len.)
-    - It enqueues a token into [deferred_tokens] such that, the next time the
-      lexer is called, it will return the specified [token] *and* set the window
-      of the lexbuf to account for the second half of the text. (The second half
-      is of length: |text|.)
-
-   This business with setting the window of the lexbuf is only so that error
-   messages point at the right place in the program text.
-*)
-let enqueue_token_from_end_of_lexbuf_window (lexbuf : Lexing.lexbuf) token ~len =
-  let suffix_end = lexbuf.lex_curr_p in
-  let suffix_start =
-    { suffix_end with pos_cnum = suffix_end.pos_cnum - len }
-  in
-  lexbuf.lex_curr_p <- suffix_start;
-  Queue.add
-    { token; start_pos = suffix_start; end_pos = suffix_end }
-    deferred_tokens
-
-(* Note [Lexing hack for float#]
-   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-   This note describes a non-backward-compatible Jane Street--internal change to
-   the lexer.
-
-   We want the lexer to lex [float#] differently than [float #]. [float#] is the
-   new syntax for the unboxed float type. It veers close to the syntax for the
-   type of all objects belonging to a class [c], which is [#c]. The way we
-   navigate this veering is by producing the following tokens for these source
-   program examples, where LIDENT(s) is an LIDENT with text [s].
-
-   float#c   ==> LIDENT(float) HASH_SUFFIX LIDENT(c)
-   float# c  ==> LIDENT(float) HASH_SUFFIX LIDENT(c)
-   float # c ==> LIDENT(float) HASH LIDENT(c)
-   float #c  ==> LIDENT(float) HASH LIDENT(c)
-
-   (A) The parser interprets [LIDENT(float) HASH_SUFFIX LIDENT(c)] as
-       "the type constructor [c] applied to the unboxed float type."
-   (B) The parser interprets [LIDENT(float) HASH LIDENT(c)] as
-       "the type constructor [#c] applied to the usual boxed float type."
-
-   This is not a backward-compatible change. In upstream ocaml, the lexer
-   produces [LIDENT(float) HASH LIDENT(c)] for all the above source programs.
-
-   But, this isn't problematic: everybody puts a space before '#c' to mean (B).
-   No existing code writes things like [float#c] or indeed [float# c].
-
-   We accomplish this hack by setting some global mutable state upon seeing
-   an identifier immediately followed by a hash. When that state is set, we
-   will produce [HASH_SUFFIX] the next time the lexer is called. This is
-   done in [enqueue_hash_suffix_from_end_of_lexbuf_window].
-
-   Note [Lexing hack for hash operators]
-   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-   To complicate the above story, we don't want to treat the # in the
-   below program as HASH_SUFFIX:
-
-   x#~#y
-
-   We instead want:
-
-   x#~#y ==> LIDENT(x) HASHOP(#~#) LIDENT(y)
-
-   This is to allow for infix hash operators. We add an additional hack, in
-   the style of Note [Lexing hack for float#], where the lexer consumes [x#~#]
-   all at once, but produces LIDENT(x) from the current call to the lexer and
-   HASHOP(#~#) from the next call to the lexer. This is done in
-   [enqueue_hashop_from_end_of_lexbuf_window].
- *)
-
-let enqueue_hash_suffix_from_end_of_lexbuf_window lexbuf =
-  enqueue_token_from_end_of_lexbuf_window lexbuf HASH_SUFFIX ~len:1
-
-let enqueue_hashop_from_end_of_lexbuf_window lexbuf ~hashop =
-  enqueue_token_from_end_of_lexbuf_window lexbuf (HASHOP hashop)
-    ~len:(String.length hashop)
-
-let lookup_keyword name =
-  match Hashtbl.find keyword_table name with
-  | kw -> kw
-  | exception Not_found ->
-     LIDENT name
-(* End Jane Street extension *)
-
 (* Escaped chars are interpreted in strings unless they are in comments. *)
 let store_escaped_char lexbuf c =
   if in_comment () then store_lexeme lexbuf else store_string_char c
 
 let store_escaped_uchar lexbuf u =
@@@@
   { start_loc with Location.loc_end = end_loc.Location.loc_end }
 
 let error lexbuf e = raise (Error(e, Location.curr lexbuf))
 let error_loc loc e = raise (Error(e, loc))
 
-(* Jane Street extension *)
-let directive_error
-    (lexbuf : Lexing.lexbuf) explanation ~directive ~already_consumed
-  =
-  let directive_prefix =
-    match already_consumed with
-    | Hash -> "#"
-    | Hash_and_line_num { line_num } -> "#" ^ line_num
-  in
-  (* Set the lexbuf's current window to extend to the start of
-     the directive so the error message's location is more accurate.
-  *)
-  lexbuf.lex_start_p <-
-    { lexbuf.lex_start_p with
-      pos_cnum =
-        lexbuf.lex_start_p.pos_cnum - String.length directive_prefix
-    };
-  error lexbuf
-    (Invalid_directive (directive_prefix ^ directive, Some explanation))
-(* End Jane Street extension *)
-
 (* to translate escape sequences *)
 
 let digit_value c =
   match c with
   | 'a' .. 'f' -> 10 + Char.code c - Char.code 'a'
@@@@
 let is_keyword name = Hashtbl.mem keyword_table name
 
 let check_label_name lexbuf name =
   if is_keyword name then error lexbuf (Keyword_as_label name)
 
-(* To "unlex" a few characters *)
-let set_lexeme_length buf n = (
-  let open Lexing in
-  if n < 0 then
-    invalid_arg "set_lexeme_length: offset should be positive";
-  if n > buf.lex_curr_pos - buf.lex_start_pos then
-    invalid_arg "set_lexeme_length: offset larger than lexeme";
-  buf.lex_curr_pos <- buf.lex_start_pos + n;
-  buf.lex_curr_p <- {buf.lex_start_p
-                     with pos_cnum = buf.lex_abs_pos + buf.lex_curr_pos};
-)
-
-let disambiguate lexbuf txt =
-  let pos = ref 0 in
-  let len = String.length txt in
-  let is_digit c = c >= '0' && c <= '9' in
-  while !pos < len && is_digit txt.[!pos] do incr pos done;
-  let txt =
-    if !pos < len then (
-      set_lexeme_length lexbuf !pos;
-      String.sub txt 0 !pos
-    ) else
-      txt
-  in
-  TYPE_DISAMBIGUATOR txt
-
-let try_disambiguate lexbuf = function
-  | INT (txt, None) -> Some (disambiguate lexbuf txt)
-  | FLOAT (txt, _)  -> Some (disambiguate lexbuf txt)
-  | _ -> None
-
 (* Update the current location with file name and line number. *)
 
 let update_loc lexbuf file line absolute chars =
   let pos = lexbuf.lex_curr_p in
   let new_file = match file with
@@@@
 
 let escaped_newlines = ref false
 
 (* Warn about Latin-1 characters used in idents *)
 
-let warn_latin1 lexbuf =
-  Location.deprecated
+let warn_latin1 lexbuf = ignore lexbuf
+  (*Location.deprecated
     (Location.curr lexbuf)
-    "ISO-Latin1 characters in identifiers"
+    "ISO-Latin1 characters in identifiers"*)
 
 let handle_docstrings = ref true
 let comment_list = ref []
 
 let add_comment com =
@@@@
   in
     add_comment com
 
 let comments () = List.rev !comment_list
 
-(* Jane Street extension *)
-let float ~maybe_hash lit modifier =
-  match maybe_hash with
-  | "#" -> HASH_FLOAT (lit, modifier)
-  | "" -> FLOAT (lit, modifier)
-  | unexpected -> fatal_error ("expected # or empty string: " ^ unexpected)
-
-let int ~maybe_hash lit modifier =
-  match maybe_hash with
-  | "#" -> HASH_INT (lit, modifier)
-  | "" -> INT (lit, modifier)
-  | unexpected -> fatal_error ("expected # or empty string: " ^ unexpected)
-(* End Jane Street extension *)
-
+(*
 (* Error report *)
 
 open Format
 
 let prepare_error loc = function
@@@@
       | Error (err, loc) ->
           Some (prepare_error loc err)
       | _ ->
           None
     )
+*)
 
 }
 
 let newline = ('\013'* '\010')
 let blank = [' ' '\009' '\012']
@@@@
       { check_label_name lexbuf name;
         OPTLABEL name }
   | "?" (lowercase_latin1 identchar_latin1 * as name) ':'
       { warn_latin1 lexbuf;
         OPTLABEL name }
-
-  (* Jane Street extension *)
-  (* Lowercase identifiers are split into 3 cases, and the order matters
-     (longest to shortest).
-  *)
-  | (lowercase identchar * as name) ('#' symbolchar_or_hash+ as hashop)
-      (* See Note [Lexing hack for hash operators] *)
-      { enqueue_hashop_from_end_of_lexbuf_window lexbuf ~hashop;
-        lookup_keyword name }
-  | (lowercase identchar * as name) '#'
-      (* See Note [Lexing hack for float#] *)
-      { enqueue_hash_suffix_from_end_of_lexbuf_window lexbuf;
-        lookup_keyword name }
-  (* End Jane Street extension *)
-
   | lowercase identchar * as name
       { try Hashtbl.find keyword_table name
         with Not_found -> LIDENT name }
-
-  (* Jane Street extension *)
-  (* Lowercase latin1 identifiers are split into 3 cases, and the order matters
-     (longest to shortest).
-  *)
-  | (lowercase_latin1 identchar_latin1 * as name)
-      ('#' symbolchar_or_hash+ as hashop)
-      (* See Note [Lexing hack for hash operators] *)
-      { warn_latin1 lexbuf;
-        enqueue_hashop_from_end_of_lexbuf_window lexbuf ~hashop;
-        LIDENT name }
-  | (lowercase_latin1 identchar_latin1 * as name) '#'
-      (* See Note [Lexing hack for float#] *)
-      { warn_latin1 lexbuf;
-        enqueue_hash_suffix_from_end_of_lexbuf_window lexbuf;
-        LIDENT name }
-  (* End Jane Street extension *)
-
   | lowercase_latin1 identchar_latin1 * as name
       { warn_latin1 lexbuf; LIDENT name }
   | uppercase identchar * as name
       { UIDENT name } (* No capitalized keywords *)
   | uppercase_latin1 identchar_latin1 * as name
       { warn_latin1 lexbuf; UIDENT name }
-
-  (* Jane Street modification *)
-  (* This matches either an integer literal or a directive. If the text "#2"
-     appears at the beginning of a line that lexes as a directive, then it
-     should be treated as a directive and not an unboxed int. This is acceptable
-     because "#2" isn't a valid unboxed int anyway because it lacks a suffix;
-     the parser rejects unboxed-ints-lacking-suffixes with a more descriptive
-     error message.
-  *)
-  | ('#'? as maybe_hash) (int_literal as lit)
-      { if at_beginning_of_line lexbuf.lex_start_p && maybe_hash = "#" then
-          try directive (Hash_and_line_num { line_num = lit }) lexbuf
-          with Failure _ -> int ~maybe_hash lit None
-        else int ~maybe_hash lit None
-      }
-  | ('#'? as maybe_hash) (int_literal as lit) (literal_modifier as modif)
-      { int ~maybe_hash lit (Some modif) }
-  | ('#'? as maybe_hash)
-    (float_literal | hex_float_literal as lit)
-      { float ~maybe_hash lit None }
-  | ('#'? as maybe_hash)
-    (float_literal | hex_float_literal as lit) (literal_modifier as modif)
-      { float ~maybe_hash lit (Some modif) }
-  | '#'? (float_literal | hex_float_literal | int_literal) identchar+ as invalid
+  | int_literal as lit { INT (lit, None) }
+  | (int_literal as lit) (literal_modifier as modif)
+      { INT (lit, Some modif) }
+  | float_literal | hex_float_literal as lit
+      { FLOAT (lit, None) }
+  | (float_literal | hex_float_literal as lit) (literal_modifier as modif)
+      { FLOAT (lit, Some modif) }
+  | (float_literal | hex_float_literal | int_literal) identchar+ as invalid
       { error lexbuf (Invalid_literal invalid) }
-  (* End Jane Street modification *)
-
   | "\""
       { let s, loc = wrap_string_lexer string lexbuf in
         STRING (s, loc, None) }
   | "{" (lowercase* as delim) "|"
       { let s, loc = wrap_string_lexer (quoted_string delim) lexbuf in
@@@@
                comment lexbuf)
             lexbuf
         in
         COMMENT (s, loc) }
   | "(*)"
-      { if !print_warnings then
-          Location.prerr_warning (Location.curr lexbuf) Warnings.Comment_start;
+      { (*if !print_warnings then
+          Location.prerr_warning (Location.curr lexbuf) Warnings.Comment_start;*)
         let s, loc = wrap_comment_lexer comment lexbuf in
         COMMENT (s, loc) }
   | "(*" (('*'*) as stars) "*)"
       { if !handle_docstrings && stars="" then
          (* (**) is an empty docstring *)
           DOCSTRING(Docstrings.docstring "" (Location.curr lexbuf))
         else
           COMMENT (stars, Location.curr lexbuf) }
   | "*)"
-      { let loc = Location.curr lexbuf in
-        Location.prerr_warning loc Warnings.Comment_not_end;
+      { (*let loc = Location.curr lexbuf in
+        Location.prerr_warning loc Warnings.Comment_not_end;*)
         lexbuf.Lexing.lex_curr_pos <- lexbuf.Lexing.lex_curr_pos - 1;
         let curpos = lexbuf.lex_curr_p in
         lexbuf.lex_curr_p <- { curpos with pos_cnum = curpos.pos_cnum - 1 };
         STAR
       }
-
-  (* Jane Street modification *)
   | "#"
-      { if not (at_beginning_of_line lexbuf.lex_start_p)
+      { let at_beginning_of_line pos = (pos.pos_cnum = pos.pos_bol) in
+        if not (at_beginning_of_line lexbuf.lex_start_p)
         then HASH
-        else try directive Hash lexbuf with Failure _ -> HASH
+        else try directive lexbuf with Failure _ -> HASH
       }
-  (* End Jane Street modification *)
-
   | "&"  { AMPERSAND }
   | "&&" { AMPERAMPER }
   | "`"  { BACKQUOTE }
   | "\'" { QUOTE }
   | "("  { LPAREN }
@@@@
   | ['+' '-'] symbolchar * as op
             { INFIXOP2 op }
   | "**" symbolchar * as op
             { INFIXOP4 op }
   | '%'     { PERCENT }
-  | '/'     { SLASH }
   | ['*' '/' '%'] symbolchar * as op
             { INFIXOP3 op }
   | '#' symbolchar_or_hash + as op
             { HASHOP op }
   | "let" kwdopchar dotsymbolchar * as op
@@@@
             { ANDOP op }
   | eof { EOF }
   | (_ as illegal_char)
       { error lexbuf (Illegal_character illegal_char) }
 
-(* Jane Street modification *)
-(* An example of a directive is:
-
-#4 "filename.ml"
-
-   Here, 4 is the line number and filename.ml is the file name. The '#' must
-   appear in column 0.
-
-   The [directive] lexer is called when some portion of the start of
-   the line was already consumed, either just the '#' or the '#4'. That's
-   indicated by the [already_consumed] argument. The caller is responsible
-   for checking that the '#' appears in column 0.
-
-   The [directive] lexer always attempts to read the line number from the
-   lexbuf. It expects to receive a line number from exactly one source (either
-   the lexbuf or the [already_consumed] argument, but not both) and will fail if
-   this isn't the case.
-*)
-and directive already_consumed = parse
-  | ([' ' '\t']* (['0'-'9']+? as _line_num_opt) [' ' '\t']*
-     ("\"" ([^ '\010' '\013' '\"' ] * as _name) "\"") as directive)
+and directive = parse
+  | ([' ' '\t']* (['0'-'9']+ as _num) [' ' '\t']*
+        ("\"" ([^ '\010' '\013' '\"' ] * as _name) "\"") as directive)
         [^ '\010' '\013'] *
       {
         (* Line directives are not preserved by the lexer so we error out. *)
         let explanation = "line directives are not supported" in
-        directive_error lexbuf explanation ~already_consumed ~directive
+        error lexbuf (Invalid_directive ("#" ^ directive, Some explanation))
       }
-(* End Jane Street modification *)
-
 and comment = parse
     "(*"
       { comment_start_loc := (Location.curr lexbuf) :: !comment_start_loc;
         store_lexeme lexbuf;
         comment lexbuf
@@@@
   | '\\' _
       { if not (in_comment ()) then begin
 (*  Should be an error, but we are very lax.
           error lexbuf (Illegal_escape (Lexing.lexeme lexbuf, None))
 *)
-          let loc = Location.curr lexbuf in
-          Location.prerr_warning loc Warnings.Illegal_backslash;
+          (*let loc = Location.curr lexbuf in
+          Location.prerr_warning loc Warnings.Illegal_backslash;*)
         end;
         store_lexeme lexbuf;
         string lexbuf
       }
   | newline
-      { if not (in_comment ()) then
-          Location.prerr_warning (Location.curr lexbuf) Warnings.Eol_in_string;
+      { (*if not (in_comment ()) then
+          Location.prerr_warning (Location.curr lexbuf) Warnings.Eol_in_string;*)
         update_loc lexbuf None 1 false 0;
         store_lexeme lexbuf;
         string lexbuf
       }
   | eof
@@@@
   | "#!" [^ '\n']* '\n'
       { update_loc lexbuf None 1 false 0 }
   | "" { () }
 
 {
-  (* Jane Street extension *)
-  let token lexbuf =
-    match Queue.take_opt deferred_tokens with
-    | None -> token lexbuf
-    | Some { token; start_pos; end_pos } ->
-        lexbuf.lex_start_p <- start_pos;
-        lexbuf.lex_curr_p <- end_pos;
-        token
-  (* End Jane Street extension *)
 
   let token_with_comments lexbuf =
     match !preprocessor with
     | None -> token lexbuf
     | Some (_init, preprocess) -> preprocess token lexbuf
--- parser-extended/parser.mly
+++ parser-recovery/lib/parser.mly
@@@@
    text comprised between the markers [BEGIN AVOID] and -----------
    [END AVOID] has been removed. This file should be formatted in
    such a way that this results in a clean removal of certain
    symbols, productions, or declarations. */
 
+/* parser-recovery:
+   Compared to upstream, rules with errors on the RHS (between [BEGIN AVOID]
+   and [END AVOID]) are commented. Some rules definition are kept to minimize
+   the diff as long as the call sites are commented. This is necessary to
+   trigger the recovery in case of invalid input, instead of triggering the
+   error rules. */
+
 %{
 
 open Asttypes
 open Longident
 open Parsetree
@@@@
   | Public -> mk_pv ()
   | Private priv -> mk_pv ~priv ()
 
 let mkvarinj s l = mkloc s (make_loc l)
 let mktyp ~loc ?attrs d = Typ.mk ~loc:(make_loc loc) ?attrs d
-let mkpat ~loc ?attrs d = Pat.mk ~loc:(make_loc loc) ?attrs d
+let mkpat ~loc d = Pat.mk ~loc:(make_loc loc) d
 let mkexp ~loc d = Exp.mk ~loc:(make_loc loc) d
 let mkmty ~loc ?attrs d = Mty.mk ~loc:(make_loc loc) ?attrs d
 let mksig ~loc d = Sig.mk ~loc:(make_loc loc) d
 let mkmod ~loc ?attrs d = Mod.mk ~loc:(make_loc loc) ?attrs d
 let mkstr ~loc d = Str.mk ~loc:(make_loc loc) d
@@@@
   AST node, then the location must be real; in all other cases,
   it must be ghost.
 *)
 let ghexp ~loc d = Exp.mk ~loc:(ghost_loc loc) d
 let ghpat ~loc d = Pat.mk ~loc:(ghost_loc loc) d
-let ghtyp ~loc ?attrs d = Typ.mk ~loc:(ghost_loc loc) ?attrs d
+let ghtyp ~loc d = Typ.mk ~loc:(ghost_loc loc) d
 let ghstr ~loc d = Str.mk ~loc:(ghost_loc loc) d
 let ghsig ~loc d = Sig.mk ~loc:(ghost_loc loc) d
 
 let mkinfix arg1 op arg2 =
   Pexp_infix(op, arg1, arg2)
 
-(* Jane Street extension *)
-let flip_sign = function
-  | Positive -> Negative
-  | Negative -> Positive
-(* End Jane Street extension *)
-
 let neg_string f =
   if String.length f > 0 && f.[0] = '-'
   then String.sub f 1 (String.length f - 1)
   else "-" ^ f
 
@@@@
   match name, arg.pexp_desc with
   | "-", Pexp_constant({pconst_desc= Pconst_integer (n,m); _} as c) ->
       Pexp_constant({c with pconst_desc= Pconst_integer(neg_string n,m)})
   | ("-" | "-."), Pexp_constant({pconst_desc= Pconst_float (f, m); _} as c) ->
       Pexp_constant({c with pconst_desc= Pconst_float(neg_string f, m)})
-
-  (* Jane Street extension *)
-  | "-", Pexp_constant({pconst_desc= Pconst_unboxed_integer (s,n,m); _} as c) ->
-      Pexp_constant({c with
-                     pconst_desc= Pconst_unboxed_integer(flip_sign s,n,m)})
-  | ("-" | "-."), Pexp_constant({pconst_desc=
-                                   Pconst_unboxed_float (s, f, m); _} as c) ->
-      Pexp_constant({c with
-                     pconst_desc= Pconst_unboxed_float(flip_sign s, f, m)})
-  (* End Jane Street extension *)
-
   | _ ->
       Pexp_prefix(mkoperator ~loc:oploc ("~" ^ name), arg)
 
 let mkuplus ~oploc name arg =
   let desc = arg.pexp_desc in
   match name, desc with
   | "+", Pexp_constant({pconst_desc= Pconst_integer _; _})
   | ("+" | "+."), Pexp_constant({pconst_desc= Pconst_float _; _}) -> desc
-
-  (* Jane Street extension *)
-  | "+", Pexp_constant({pconst_desc= Pconst_unboxed_integer _; _})
-  | ("+" | "+."), Pexp_constant({pconst_desc= Pconst_unboxed_float _; _})
-    -> desc
-  (* End Jane Street extension *)
-
   | _ ->
       Pexp_prefix(mkoperator ~loc:oploc ("~" ^ name), arg)
 
 
 let local_ext_loc = mknoloc "extension.local"
@@@@
   Attr.mk ~loc:Location.none local_ext_loc (PStr [])
 
 let local_extension =
   Exp.mk ~loc:Location.none (Pexp_extension(local_ext_loc, PStr []))
 
-let include_functor_ext_loc = mknoloc "extension.include_functor"
-
-let include_functor_attr =
-  Attr.mk ~loc:Location.none include_functor_ext_loc (PStr [])
-
 let mkexp_stack ~loc exp =
-  if Erase_jane_syntax.should_erase () then exp else
   ghexp ~loc (Pexp_apply(local_extension, [Nolabel, exp]))
 
 let mkpat_stack pat =
-  if Erase_jane_syntax.should_erase () then pat else
   {pat with ppat_attributes = local_attr :: pat.ppat_attributes}
 
 let mktyp_stack typ =
-  if Erase_jane_syntax.should_erase () then typ else
   {typ with ptyp_attributes = local_attr :: typ.ptyp_attributes}
 
 let wrap_exp_stack exp =
-  if Erase_jane_syntax.should_erase () then exp else
   {exp with pexp_attributes = local_attr :: exp.pexp_attributes}
 
 let mkexp_local_if p ~loc exp =
   if p then mkexp_stack ~loc exp else exp
 
@@@@
 let exclave_extension loc =
   Exp.mk ~loc:Location.none
     (Pexp_extension(exclave_ext_loc loc, PStr []))
 
 let mkexp_exclave ~loc ~kwd_loc exp =
-  if Erase_jane_syntax.should_erase () then exp else
   ghexp ~loc (Pexp_apply(exclave_extension (make_loc kwd_loc), [Nolabel, exp]))
 
 let curry_attr =
   Attr.mk ~loc:Location.none (mknoloc "extension.curry") (PStr [])
 
 let is_curry_attr attr =
   attr.attr_name.txt = "extension.curry"
 
 let mktyp_curry typ =
-  if Erase_jane_syntax.should_erase () then typ else
   {typ with ptyp_attributes = curry_attr :: typ.ptyp_attributes}
 
 let maybe_curry_typ typ =
   match typ.ptyp_desc with
   | Ptyp_arrow _ ->
@@@@
 
 let global_attr loc =
   Attr.mk ~loc:Location.none (global_loc loc) (PStr [])
 
 let mkld_global ld loc =
-  if Erase_jane_syntax.should_erase () then ld else
-  { ld with pld_attributes = global_attr loc :: ld.pld_attributes }
+  { ld with pld_attributes = (global_attr loc) :: ld.pld_attributes }
 
 let mkld_global_maybe gbl ld loc =
   match gbl with
   | Global -> mkld_global ld loc
   | Nothing -> ld
 
 let mkcty_global cty loc =
-  if Erase_jane_syntax.should_erase () then cty else
   { cty with ptyp_attributes = global_attr loc :: cty.ptyp_attributes }
 
 let mkcty_global_maybe gbl cty loc =
   match gbl with
   | Global -> mkcty_global cty loc
@@@@
   match t1, t2 with
   | Some t, None -> mkexp ~loc (Pexp_constraint(e, t))
   | _, Some t -> mkexp ~loc (Pexp_coerce(e, t1, t))
   | None, None -> assert false
 
-let syntax_error () =
-  raise Syntaxerr.Escape_error
-
-let unclosed opening_name opening_loc closing_name closing_loc =
-  raise(Syntaxerr.Error(Syntaxerr.Unclosed(make_loc opening_loc, opening_name,
-                                           make_loc closing_loc, closing_name)))
-
 (* Normal mutable arrays and immutable arrays are parsed identically, just with
    different delimiters.  The parsing is done by the [array_exprs] rule, and the
    [Generic_array] module provides (1) a type representing the possible results,
    and (2) a function for going from that type to an AST fragment representing
    an array. *)
@@@@
                        Lexing.position *
                        expression list
                      -> (expression, expression_desc) t
     (** An array literal with a local open, [Module.[? x; y; z ?]] (only valid in
         expressions) *)
-    | Unclosed : (Lexing.position * Lexing.position) *
+    (*| Unclosed : (Lexing.position * Lexing.position) *
                  (Lexing.position * Lexing.position)
                -> (_, _) t
     (** Parse error: an unclosed array literal, [\[? x; y; z] with no closing
-        [?\]]. *)
+        [?\]]. *)*)
 
   let to_ast (type ast ast_desc)
-             (open_ : string) (close : string)
+             (_open_ : string) (_close : string)
              (array : ast list -> ast_desc)
         : (ast, ast_desc) t -> ast_desc = function
     | Literal elts ->
         array elts
     | Opened_literal(od, startpos, endpos, elts) ->
         (Pexp_open(od, mkexp ~loc:(startpos, endpos) (array elts)) : ast_desc)
-    | Unclosed(startpos, endpos) ->
-        unclosed open_ startpos close endpos
+    (*| Unclosed(startpos, endpos) ->
+        unclosed open_ startpos close endpos*)
 
   let expression : _ -> _ -> _ -> (expression, expression_desc) t -> _ = to_ast
   let pattern    : _ -> _ -> _ -> (pattern,    pattern_desc)    t -> _ = to_ast
 end
 
 let ppat_iarray loc elts =
   (Extensions.Immutable_arrays.pat_of
      ~loc:(make_loc loc)
      (Iapat_immutable_array elts)).ppat_desc
 
-let expecting_loc (loc : Location.t) (nonterm : string) =
-    raise Syntaxerr.(Error(Expecting(loc, nonterm)))
-let expecting (loc : Lexing.position * Lexing.position) nonterm =
-     expecting_loc (make_loc loc) nonterm
-
 (* Using the function [not_expecting] in a semantic action means that this
    syntactic form is recognized by the parser but is in fact incorrect. This
    idiom is used in a few places to produce ad hoc syntax error messages. *)
 
 (* This idiom should be used as little as possible, because it confuses the
@@@@
    (unexpected) syntax error and do not achieve the desired effect. This could
    also lead a completion system to propose completions which in fact are
    incorrect. In order to avoid these problems, the productions that use
    [not_expecting] should be marked with AVOID. *)
 
-let not_expecting loc nonterm =
-    raise Syntaxerr.(Error(Not_expecting(make_loc loc, nonterm)))
-
 let mk_builtin_indexop_expr ~loc (pia_lhs, _dot, pia_paren, idx, pia_rhs) =
   mkexp ~loc
     (Pexp_indexop_access
        { pia_lhs; pia_kind= Builtin idx; pia_paren; pia_rhs })
 
 let mk_dotop_indexop_expr ~loc (pia_lhs, (path, op), pia_paren, idx, pia_rhs) =
   mkexp ~loc
     (Pexp_indexop_access
        { pia_lhs; pia_kind= Dotop (path, op, idx); pia_paren; pia_rhs })
 
-let paren_to_strings = function
-  | Paren -> "(", ")"
-  | Bracket -> "[", "]"
-  | Brace -> "{", "}"
-
-let indexop_unclosed_error loc_s s loc_e =
-  let left, right = paren_to_strings s in
-  unclosed left loc_s right loc_e
-
 let lapply ~loc p1 p2 =
   if !Clflags.applicative_functors
   then Lapply(p1, p2)
   else raise (Syntaxerr.Error(
                   Syntaxerr.Applicative_path (make_loc loc)))
 
+(* [loc_map] could be [Location.map]. *)
+let loc_map (f : 'a -> 'b) (x : 'a Location.loc) : 'b Location.loc =
+  { x with txt = f x.txt }
+
 let make_ghost x = { x with loc = { x.loc with loc_ghost = true }}
 
 let loc_last (id : Longident.t Location.loc) : string Location.loc =
-  Location.map Longident.last id
+  loc_map Longident.last id
 
 let loc_lident (id : string Location.loc) : Longident.t Location.loc =
-  Location.map (fun x -> Lident x) id
+  loc_map (fun x -> Lident x) id
 
 let exp_of_label lbl =
   Exp.mk ~loc:lbl.loc (Pexp_ident (loc_lident lbl))
 
 let mk_newtypes ~loc newtypes exp =
   let mkexp = mkexp ~loc in
-  List.fold_right (fun newtype exp -> mkexp (Pexp_newtype (newtype, exp)))
+  List.fold_right (fun newtype exp -> mkexp (Pexp_newtype (
+    Location.map (fun name -> (Some name, None)) newtype, exp)))
     newtypes exp
 
 let wrap_type_annotation ~loc newtypes core_type body =
   let mkexp, ghtyp = mkexp ~loc, ghtyp ~loc in
   let mk_newtypes = mk_newtypes ~loc in
   let exp = mkexp(Pexp_constraint(body,core_type)) in
   let exp = mk_newtypes newtypes exp in
+  let newtypes = List.map (fun name_loc ->
+    mkloc (Some name_loc.txt, None) (make_loc loc)) newtypes in
   (exp, ghtyp(Ptyp_poly(newtypes, core_type)))
 
 let wrap_exp_attrs ~loc body (ext, attrs) =
   let ghexp = ghexp ~loc in
   (* todo: keep exact location for the entire attribute *)
   let body = {body with pexp_attributes = attrs @ body.pexp_attributes} in
   match ext with
   | None -> body
   | Some id -> ghexp(Pexp_extension (id, PStr [mkstrexp body []]))
 
-let mkexp_attrs ~loc d ext_attrs =
-  wrap_exp_attrs ~loc (mkexp ~loc d) ext_attrs
+let mkexp_attrs ~loc d attrs =
+  wrap_exp_attrs ~loc (mkexp ~loc d) attrs
 
 let wrap_typ_attrs ~loc typ (ext, attrs) =
   (* todo: keep exact location for the entire attribute *)
   let typ = {typ with ptyp_attributes = attrs @ typ.ptyp_attributes} in
   match ext with
@@@@
 let text_str pos = Str.text (rhs_text pos)
 let text_sig pos = Sig.text (rhs_text pos)
 let text_cstr pos = Cf.text (rhs_text pos)
 let text_csig pos = Ctf.text (rhs_text pos)
 let text_def pos =
-  List.map (fun def -> Ptop_def [def]) (Str.text (rhs_text pos))
+  (* Change required for parser-recovery *)
+  [Ptop_def (Str.text (rhs_text pos))]
+  (*List.map (fun def -> Ptop_def [def]) (Str.text (rhs_text pos))*)
 
 let extra_text startpos endpos text items =
   match items with
   | [] ->
       let post = rhs_post_text endpos in
@@@@
     lb_attributes = add_text_attrs text (add_docs_attrs docs attrs);
     lb_loc = make_loc loc;
   }
 
 let addlb lbs lb =
-  if lb.lb_is_pun && lbs.lbs_extension = None then syntax_error ();
+  (*if lb.lb_is_pun && lbs.lbs_extension = None then syntax_error ();*)
   { lbs with lbs_bindings = lb :: lbs.lbs_bindings }
 
 let mklbs ext rf lb =
   let lbs = {
     lbs_bindings = [];
@@@@
       pdir_name = name;
       pdir_arg = arg;
       pdir_loc = make_loc loc;
     }
 
-let check_layout ~loc id : const_layout =
-  match id with
-  | "any" -> Any
-  | "value" -> Value
-  | "void" -> Void
-  | "immediate64" -> Immediate64
-  | "immediate" -> Immediate
-  | "float64" -> Float64
-  | _ -> expecting_loc loc "layout"
+let check_layout loc id =
+  begin
+    match id with
+    | ("any" | "value" | "void" | "immediate64" | "immediate") -> ()
+    | _ -> raise Syntaxerr.(Error(Expecting(make_loc loc, "layout")))
+  end;
+  let loc = make_loc loc in
+  Attr.mk ~loc (mkloc id loc) (PStr [])
+
 %}
 
 /* Tokens */
 
 /* The alias that follows each token is used by Menhir when it needs to
@@@@
 %token BAR                    "|"
 %token BARBAR                 "||"
 %token BARRBRACKET            "|]"
 %token BEGIN                  "begin"
 %token <char> CHAR            "'a'" (* just an example *)
+  [@recover.expr '?']
 %token CLASS                  "class"
 %token COLON                  ":"
 %token COLONCOLON             "::"
 %token COLONEQUAL             ":="
 %token COLONGREATER           ":>"
@@@@
 %token EXCEPTION              "exception"
 %token EXCLAVE                "exclave_"
 %token EXTERNAL               "external"
 %token FALSE                  "false"
 %token <string * char option> FLOAT "42.0" (* just an example *)
+  [@recover.expr ("<invalid-float>", None)]
 %token FOR                    "for"
 %token FUN                    "fun"
 %token FUNCTION               "function"
 %token FUNCTOR                "functor"
 %token GLOBAL                 "global_"
@@@@
 %token <string> LETOP         "let*" (* just an example *)
 %token <string> ANDOP         "and*" (* just an example *)
 %token INHERIT                "inherit"
 %token INITIALIZER            "initializer"
 %token <string * char option> INT "42"  (* just an example *)
+  [@recover.expr ("<invalid-int>", None)]
 %token <string> LABEL         "~label:" (* just an example *)
+  [@recover.expr "<invalid-label>"]
 %token LAZY                   "lazy"
 %token LBRACE                 "{"
 %token LBRACELESS             "{<"
 %token LBRACKET               "["
 %token LBRACKETBAR            "[|"
@@@@
 %token LBRACKETPERCENTPERCENT "[%%"
 %token LESS                   "<"
 %token LESSMINUS              "<-"
 %token LET                    "let"
 %token <string> LIDENT        "lident" (* just an example *)
+  [@recover.expr "<invalid-lident>"]
 %token LOCAL                  "local_"
 %token LPAREN                 "("
 %token LBRACKETAT             "[@"
 %token LBRACKETATAT           "[@@"
 %token LBRACKETATATAT         "[@@@"
@@@@
 %token PERCENT                "%"
 %token PLUS                   "+"
 %token PLUSDOT                "+."
 %token PLUSEQ                 "+="
 %token <string> PREFIXOP      "!+" (* chosen with care; see above *)
+  [@recover.expr "<invalid-prefixop>"]
 %token PRIVATE                "private"
 %token QUESTION               "?"
 %token QUOTE                  "'"
 %token RBRACE                 "}"
 %token RBRACKET               "]"
@@@@
 %token SIG                    "sig"
 %token SLASH                  "/"
 %token STAR                   "*"
 %token <string * Location.t * string option>
        STRING                 "\"hello\"" (* just an example *)
+  [@recover.expr ("<invalid-string>", Location.none, Some "<invalid-string>")]
 %token <string * Location.t * string * Location.t * string option>
        QUOTED_STRING_EXPR     "{%hello|world|}"  (* just an example *)
 %token <string * Location.t * string * Location.t * string option>
        QUOTED_STRING_ITEM     "{%%hello|world|}" (* just an example *)
 %token STRUCT                 "struct"
@@@@
 %token TO                     "to"
 %token TRUE                   "true"
 %token TRY                    "try"
 %token TYPE                   "type"
 %token <string> UIDENT        "UIdent" (* just an example *)
+  [@recover.expr "<invalid-uident>"]
 %token UNDERSCORE             "_"
 %token VAL                    "val"
 %token VIRTUAL                "virtual"
 %token WHEN                   "when"
 %token WHILE                  "while"
@@@@
 
 %token EOL                    "\\n"      (* not great, but EOL is unused *)
 
 %token <string> TYPE_DISAMBIGUATOR "2" (* just an example *)
 
-(* Jane Street extension *)
-%token <string * char option> HASH_FLOAT "#42.0" (* just an example *)
-%token <string * char option> HASH_INT "#42l" (* just an example *)
-%token                        HASH_SUFFIX "# "
-(* End Jane Street extension *)
-
 /* Precedences and associativities.
 
 Tokens and rules have precedences.  A reduce/reduce conflict is resolved
 in favor of the first rule (in source file order).  A shift/reduce conflict
 is resolved by comparing the precedence and associativity of the token to
@@@@
 %right    COLONEQUAL                    /* expr (e := e := e) */
 %nonassoc AS
 %left     BAR                           /* pattern (p|p|p) */
 %nonassoc below_COMMA
 %left     COMMA                         /* expr/expr_comma_list (e,e,e) */
-%nonassoc below_FUNCTOR                 /* include M */
-%nonassoc FUNCTOR                       /* include functor M */
 %right    MINUSGREATER                  /* function_type (t -> t -> t) */
 %right    OR BARBAR                     /* expr (e || e || e) */
 %right    AMPERSAND AMPERAMPER          /* expr (e && e && e) */
 %nonassoc below_EQUAL
 %left     INFIXOP0 EQUAL LESS GREATER   /* expr (e OP e OP e) */
@@@@
 %right    INFIXOP4                      /* expr (e OP e OP e) */
 %nonassoc prec_unary_minus prec_unary_plus /* unary - */
 %nonassoc prec_constant_constructor     /* cf. simple_expr (C versus C x) */
 %nonassoc prec_constr_appl              /* above AS BAR COLONCOLON COMMA */
 %nonassoc below_HASH
-%nonassoc HASH HASH_SUFFIX              /* simple_expr/toplevel_directive */
+%nonassoc HASH                         /* simple_expr/toplevel_directive */
 %left     HASHOP
 %nonassoc below_DOT
 %nonassoc DOT DOTOP
 /* Finally, the first tokens of simple_expr are above everything else. */
-%nonassoc BACKQUOTE BANG BEGIN CHAR FALSE FLOAT HASH_FLOAT INT HASH_INT OBJECT
+%nonassoc BACKQUOTE BANG BEGIN CHAR FALSE FLOAT INT OBJECT
           LBRACE LBRACELESS LBRACKET LBRACKETBAR LBRACKETCOLON LIDENT LPAREN
           NEW PREFIXOP STRING TRUE UIDENT UNDERSCORE
           LBRACKETPERCENT QUOTED_STRING_EXPR
 
 
@@@@
 (* The syntax of module expressions is not properly stratified. The cases of
    functors, functor applications, and attributes interact and cause conflicts,
    which are resolved by precedence declarations. This is concise but fragile.
    Perhaps in the future an explicit stratification could be used. *)
 
-module_expr:
+module_expr [@recover.expr Annot.Mod.mk ()]:
   | STRUCT attrs = attributes s = structure END
       { mkmod ~loc:$sloc ~attrs (Pmod_structure s) }
-  | STRUCT attributes structure error
-      { unclosed "struct" $loc($1) "end" $loc($4) }
-  | SIG error
-      { expecting $loc($1) "struct" }
   | FUNCTOR attrs = attributes args = functor_args MINUSGREATER me = module_expr
       { wrap_mod_attrs ~loc:$sloc attrs (
           List.fold_left (fun acc (startpos, arg) ->
             mkmod ~loc:(startpos, $endpos) (Pmod_functor (arg, acc))
           ) me args
@@@@
 
 paren_module_expr:
     (* A module expression annotated with a module type. *)
     LPAREN me = module_expr COLON mty = module_type RPAREN
       { mkmod ~loc:$sloc (Pmod_constraint(me, mty)) }
-  | LPAREN module_expr COLON module_type error
-      { unclosed "(" $loc($1) ")" $loc($5) }
   | (* A module expression within parentheses. *)
     LPAREN me = module_expr RPAREN
       { me (* TODO consider reloc *) }
-  | LPAREN module_expr error
-      { unclosed "(" $loc($1) ")" $loc($3) }
   | (* A core language expression that produces a first-class module.
        This expression can be annotated in various ways. *)
     LPAREN VAL attrs = attributes e = expr_colon_package_type RPAREN
       { let (e, ty1, ty2) = e in
         mkmod ~loc:$sloc ~attrs (Pmod_unpack (e, ty1, ty2)) }
-  | LPAREN VAL attributes expr COLON error
-      { unclosed "(" $loc($1) ")" $loc($6) }
-  | LPAREN VAL attributes expr COLONGREATER error
-      { unclosed "(" $loc($1) ")" $loc($6) }
-  | LPAREN VAL attributes expr error
-      { unclosed "(" $loc($1) ")" $loc($5) }
 ;
 
 (* The various ways of annotating a core language expression that
    produces a first-class module that we wish to unpack. *)
 %inline expr_colon_package_type:
@@@@
 
 (* The body (right-hand side) of a module binding. *)
 module_binding_body:
     EQUAL me = module_expr
       { me }
-  | COLON error
-      { expecting $loc($1) "=" }
   | mkmod(
       COLON mty = module_type EQUAL me = module_expr
         { Pmod_constraint(me, mty) }
     | arg_and_pos = functor_arg body = module_binding_body
         { let (_, arg) = arg_and_pos in
@@@@
 
 (* -------------------------------------------------------------------------- *)
 
 (* Shared material between structures and signatures. *)
 
-include_and_functor_attr:
-  | INCLUDE %prec below_FUNCTOR
-      { [] }
-  | INCLUDE FUNCTOR
-      { [include_functor_attr] }
-;
-
 (* An [include] statement can appear in a structure or in a signature,
    which is why this definition is parameterized. *)
 %inline include_statement(thing):
-  attrs0 = include_and_functor_attr
+  INCLUDE
   ext = ext
   attrs1 = attributes
   thing = thing
   attrs2 = post_item_attributes
   {
-    let attrs = attrs0 @ attrs1 @ attrs2 in
+    let attrs = attrs1 @ attrs2 in
     let loc = make_loc $sloc in
     let docs = symbol_docs $sloc in
     Incl.mk thing ~attrs ~loc ~docs, ext
   }
 ;
@@@@
 
 (* -------------------------------------------------------------------------- *)
 
 /* Module types */
 
-module_type:
+module_type [@recover.expr Annot.Mty.mk ()]:
   | SIG attrs = attributes s = signature END
       { mkmty ~loc:$sloc ~attrs (Pmty_signature s) }
-  | SIG attributes signature error
-      { unclosed "sig" $loc($1) "end" $loc($4) }
-  | STRUCT error
-      { expecting $loc($1) "sig" }
   | FUNCTOR attrs = attributes args = functor_args
     MINUSGREATER mty = module_type
       %prec below_WITH
       { wrap_mty_attrs ~loc:$sloc attrs (
           List.fold_left (fun acc (startpos, arg) ->
@@@@
         ) }
   | MODULE TYPE OF attributes module_expr %prec below_LBRACKETAT
       { mkmty ~loc:$sloc ~attrs:$4 (Pmty_typeof $5) }
   | LPAREN module_type RPAREN
       { $2 }
-  | LPAREN module_type error
-      { unclosed "(" $loc($1) ")" $loc($3) }
   | module_type attribute
       { Mty.attr $1 $2 }
   | mkmty(
       mkrhs(mty_longident)
         { Pmty_ident $1 }
-    | LPAREN RPAREN MINUSGREATER module_type
-        { Pmty_functor(Unit, $4) }
     | module_type MINUSGREATER module_type
         %prec below_WITH
         { Pmty_functor(Named (mknoloc None, $1), $3) }
     | module_type WITH separated_nonempty_llist(AND, with_constraint)
         { Pmty_with($1, $3) }
 /*  | LPAREN MODULE mkrhs(mod_longident) RPAREN
         { Pmty_alias $3 } */
-    | module_type WITH mkrhs(mod_ext_longident)
-        { Pmty_strengthen($1,$3) }
     | extension
         { Pmty_extension $1 }
     )
     { $1 }
 ;
@@@@
 
 (* The body (right-hand side) of a module declaration. *)
 module_declaration_body:
     COLON mty = module_type
       { mty }
-  | EQUAL error
-      { expecting $loc($1) ":" }
   | mkmty(
       arg_and_pos = functor_arg body = module_declaration_body
         { let (_, arg) = arg_and_pos in
           Pmty_functor(arg, body) }
     )
@@@@
     let attrs = attrs1 @ attrs2 in
     let loc = make_loc $sloc in
     let docs = symbol_docs $sloc in
     Ms.mk uid body ~attrs ~loc ~docs, ext
   }
-| MODULE ext attributes mkrhs(UIDENT) COLONEQUAL error
-    { expecting $loc($6) "module path" }
 ;
 
 (* A group of recursive module declarations. *)
 %inline rec_module_declarations:
   xlist(rec_module_declaration, and_module_declaration)
@@@@
 
 (* -------------------------------------------------------------------------- *)
 
 (* Class expressions. *)
 
-class_expr:
+class_expr [@recover.expr Annot.Cl.mk ()]:
     class_simple_expr
       { $1 }
   | FUN attributes class_fun_def
       { wrap_class_attrs ~loc:$sloc $3 $2 }
   | let_bindings(no_ext) IN class_expr
@@@@
     ) { $1 }
 ;
 class_simple_expr:
   | LPAREN class_expr RPAREN
       { $2 }
-  | LPAREN class_expr error
-      { unclosed "(" $loc($1) ")" $loc($3) }
   | mkclass(
       tys = actual_class_parameters cid = mkrhs(class_longident)
         { Pcl_constr(cid, tys) }
-    | OBJECT attributes class_structure error
-        { unclosed "object" $loc($1) "end" $loc($4) }
     | LPAREN class_expr COLON class_type RPAREN
         { Pcl_constraint($2, $4) }
-    | LPAREN class_expr COLON class_type error
-        { unclosed "(" $loc($1) ")" $loc($5) }
     ) { $1 }
   | OBJECT attributes class_structure END
     { mkclass ~loc:$sloc ~attrs:$2 (Pcl_structure $3) }
 ;
 
@@@@
     COLON poly_type EQUAL seq_expr
       { let poly_exp =
           let loc = ($startpos($6), $endpos($8)) in
           ghexp ~loc (Pexp_poly($8, Some $6)) in
         ($4, pv_of_priv $3, Cfk_concrete ($1, poly_exp)), $2 }
-  | override_flag attributes private_flag mkrhs(label) COLON TYPE newtypes
+  | override_flag attributes private_flag mkrhs(label) COLON TYPE lident_list
     DOT core_type EQUAL seq_expr
       { let poly_exp_loc = ($startpos($7), $endpos($11)) in
         let poly_exp =
           let exp, poly =
             (* it seems odd to use the global ~loc here while poly_exp_loc
@@@@
         Cfk_concrete ($1, poly_exp)), $2 }
 ;
 
 /* Class types */
 
-class_type:
+class_type [@recover.expr Annot.Cty.mk ()]:
     class_signature
       { $1 }
   | mkcty(
       label = arg_label
       domain = tuple_type
@@@@
     | extension
         { Pcty_extension $1 }
     ) { $1 }
   | OBJECT attributes class_sig_body END
       { mkcty ~loc:$sloc ~attrs:$2 (Pcty_signature $3) }
-  | OBJECT attributes class_sig_body error
-      { unclosed "object" $loc($1) "end" $loc($4) }
   | class_signature attribute
       { Cty.attr $1 $2 }
   | LET OPEN override_flag attributes mkrhs(mod_longident) IN class_signature
       { let loc = ($startpos($2), $endpos($5)) in
         let od = Opn.mk ~override:$3 ~loc:(make_loc loc) $5 in
@@@@
   | x = label_var COLON cty = core_type
       { let lab, pat = x in
         lab,
         mkpat ~loc:$sloc (Ppat_constraint (pat, cty)) }
   | x = label_var COLON
-          cty = mktyp (vars = typevar_list DOT ty = core_type
-                  { Ptyp_poly (vars, ty) })
+          cty = mktyp (vars = typevar_list DOT ty = core_type { Ptyp_poly(vars, ty) })
       { let lab, pat = x in
         lab,
         mkpat ~loc:$sloc (Ppat_constraint (pat, cty)) }
 ;
 %inline label_var:
@@@@
       { $1 }
   | poly_pattern
       { $1 }
 ;
 %inline poly_pattern:
-    mkpat(
-      pat = pattern
+  mkpat(
+    pat = pattern
       COLON
       cty = mktyp(vars = typevar_list DOT ty = core_type
-              { Ptyp_poly (vars, ty) })
+              { Ptyp_poly(vars, ty) })
         { Ppat_constraint(pat, cty) })
       { $1 }
 ;
 
 %inline indexop_expr(dot, index, right):
@@@@
     { array, d, Brace,   i, r }
   | array=simple_expr d=dot LBRACKET i=index RBRACKET r=right
     { array, d, Bracket, i, r }
 ;
 
-%inline indexop_error(dot, index):
-  | simple_expr dot _p=LPAREN index  _e=error
-    { indexop_unclosed_error $loc(_p)  Paren $loc(_e) }
-  | simple_expr dot _p=LBRACE index  _e=error
-    { indexop_unclosed_error $loc(_p) Brace $loc(_e) }
-  | simple_expr dot _p=LBRACKET index  _e=error
-    { indexop_unclosed_error $loc(_p) Bracket $loc(_e) }
-;
-
 %inline qualified_dotop: ioption(DOT mkrhs(mod_longident) {$2}) DOTOP { $1, $2 };
 
-expr:
+expr [@recover.expr Annot.Exp.mk ()]:
     simple_expr %prec below_HASH
       { $1 }
   | expr_attrs
       { let desc, attrs = $1 in
         mkexp_attrs ~loc:$sloc desc attrs }
@@@@
       { mkexp ~loc:$sloc (Pexp_setfield($1, $3, $5)) }
   | indexop_expr(DOT, seq_expr, LESSMINUS v=expr {Some v})
     { mk_builtin_indexop_expr ~loc:$sloc $1 }
   | indexop_expr(qualified_dotop, expr_semi_list, LESSMINUS v=expr {Some v})
     { mk_dotop_indexop_expr ~loc:$sloc $1 }
-  | FUN ext_attributes LPAREN TYPE newtypes RPAREN fun_def
-    { let loc = $sloc in
-      wrap_exp_attrs ~loc (mk_newtypes ~loc $5 $7) $2 }
-  | FUN ext_attributes LPAREN TYPE
-    newtype=mkrhs(name=LIDENT COLON layout=layout_annotation { Some name, Some layout })
-    RPAREN fun_def
-    { let loc = $sloc in
-      wrap_exp_attrs ~loc (mk_newtypes ~loc:$sloc [newtype] $7) $2 }
   | expr attribute
       { Exp.attr $1 $2 }
 /* BEGIN AVOID */
   (*
   | UNDERSCORE
@@@@
       { Pexp_function $3, $2 }
   | FUN ext_attributes labeled_simple_pattern fun_def
       { let ext, attrs = $2 in
         let (l,o,p) = $3 in
         Pexp_fun(l, o, p, $4), (ext, attrs) }
+  | FUN ext_attributes LPAREN TYPE lident_list RPAREN fun_def
+      { let ext, attrs = $2 in
+        (mk_newtypes ~loc:$sloc $5 $7).pexp_desc, (ext, attrs) }
   | MATCH ext_attributes seq_expr WITH match_cases
       { Pexp_match($3, $5), $2 }
   | TRY ext_attributes seq_expr WITH match_cases
       { Pexp_try($3, $5), $2 }
-  | TRY ext_attributes seq_expr WITH error
-      { syntax_error() }
   | IF ext_attributes seq_expr THEN expr ELSE else_=expr
       { let ext, attrs = $2 in
         let br = { if_cond = $3; if_body = $5; if_attrs = attrs } in
         let ite =
           match else_.pexp_desc with
@@@@
       { Pexp_lazy $3, $2 }
 ;
 %inline do_done_expr:
   | DO e = seq_expr DONE
       { e }
-  | DO seq_expr error
-      { unclosed "do" $loc($1) "done" $loc($2) }
 ;
 %inline expr_:
   | simple_expr nonempty_llist(labeled_simple_expr)
       { Pexp_apply($1, $2) }
   | expr_comma_list %prec below_COMMA
@@@@
   | LPAREN e = seq_expr RPAREN
       { match e.pexp_desc with
         | Pexp_pack _ ->
             mkexp ~loc:$sloc (Pexp_parens e)
         | _ -> reloc_exp ~loc:$sloc e }
-  | LPAREN seq_expr error
-      { unclosed "(" $loc($1) ")" $loc($3) }
   | LPAREN seq_expr type_constraint RPAREN
       { mkexp_constraint ~loc:$sloc $2 $3 }
   | indexop_expr(DOT, seq_expr, { None })
       { mk_builtin_indexop_expr ~loc:$sloc $1 }
   (* Immutable array indexing is a regular operator, so it doesn't need its own
      rule and is handled by the next case *)
   | indexop_expr(qualified_dotop, expr_semi_list, { None })
       { mk_dotop_indexop_expr ~loc:$sloc $1 }
-  | indexop_error (DOT, seq_expr) { $1 }
-  | indexop_error (qualified_dotop, expr_semi_list) { $1 }
   | simple_expr_attrs
     { let desc, attrs = $1 in
       mkexp_attrs ~loc:$sloc desc attrs }
   | mkexp(simple_expr_)
       { $1 }
@@@@
 %inline simple_expr_attrs:
   | BEGIN ext_attributes seq_expr END
       { Pexp_beginend $3, $2 }
   | BEGIN ext_attributes END
       { Pexp_construct (mkloc (Lident "()") (make_loc $sloc), None), $2 }
-  | BEGIN ext_attributes seq_expr error
-      { unclosed "begin" $loc($1) "end" $loc($4) }
   | NEW ext_attributes mkrhs(class_longident)
       { Pexp_new($3), $2 }
   | LPAREN MODULE ext_attributes module_expr RPAREN
       { Pexp_pack ($4, None), $3 }
   | LPAREN MODULE ext_attributes module_expr COLON package_type RPAREN
       { Pexp_pack ($4, Some $6), $3 }
-  | LPAREN MODULE ext_attributes module_expr COLON error
-      { unclosed "(" $loc($1) ")" $loc($6) }
   | OBJECT ext_attributes class_structure END
       { Pexp_object $3, $2 }
-  | OBJECT ext_attributes class_structure error
-      { unclosed "object" $loc($1) "end" $loc($4) }
 ;
 
 comprehension_iterator:
   | EQUAL expr direction_flag expr
       { Extensions.Comprehensions.Range { start = $2 ; stop = $4 ; direction = $3 } }
@@@@
 ;
 
 %inline array_simple(ARR_OPEN, ARR_CLOSE, contents_semi_list):
   | ARR_OPEN contents_semi_list ARR_CLOSE
       { Generic_array.Literal $2 }
-  | ARR_OPEN contents_semi_list error
-      { Generic_array.Unclosed($loc($1),$loc($3)) }
   | ARR_OPEN ARR_CLOSE
       { Generic_array.Literal [] }
 ;
 
 %inline array_exprs(ARR_OPEN, ARR_CLOSE):
@@@@
   | od=open_dot_declaration DOT ARR_OPEN expr_semi_list ARR_CLOSE
       { Generic_array.Opened_literal(od, $startpos($3), $endpos, $4) }
   | od=open_dot_declaration DOT ARR_OPEN ARR_CLOSE
       { (* TODO: review the location of Pexp_array *)
         Generic_array.Opened_literal(od, $startpos($3), $endpos, []) }
-  | mod_longident DOT
-    ARR_OPEN expr_semi_list error
-      { Generic_array.Unclosed($loc($3), $loc($5)) }
 ;
 
 %inline array_patterns(ARR_OPEN, ARR_CLOSE):
   | array_simple(ARR_OPEN, ARR_CLOSE, pattern_semi_list)
       { $1 }
 ;
 
-(* Jane Street extension *)
-%inline hash:
-    | HASH { () }
-    | HASH_SUFFIX { () }
-;
-(* End Jane Street extension *)
-
 %inline simple_expr_:
   | mkrhs(val_longident)
       { Pexp_ident ($1) }
   | constant
       { Pexp_constant $1 }
@@@@
       { Pexp_prefix($1, $2) }
   | op(BANG {"!"}) simple_expr
       { Pexp_prefix($1, $2) }
   | LBRACELESS object_expr_content GREATERRBRACE
       { Pexp_override $2 }
-  | LBRACELESS object_expr_content error
-      { unclosed "{<" $loc($1) ">}" $loc($3) }
   | LBRACELESS GREATERRBRACE
       { Pexp_override [] }
   | simple_expr DOT mkrhs(label_longident)
       { Pexp_field($1, $3) }
   | od=open_dot_declaration DOT LPAREN seq_expr RPAREN
       { Pexp_open(od, $4) }
   | od=open_dot_declaration DOT LBRACELESS object_expr_content GREATERRBRACE
       { (* TODO: review the location of Pexp_override *)
         Pexp_open(od, mkexp ~loc:$sloc (Pexp_override $4)) }
-  | mod_longident DOT LBRACELESS object_expr_content error
-      { unclosed "{<" $loc($3) ">}" $loc($5) }
-  | simple_expr hash mkrhs(label)
+  | simple_expr HASH mkrhs(label)
       { Pexp_send($1, $3) }
   | simple_expr op(HASHOP) simple_expr
       { mkinfix $1 $2 $3 }
   | extension
       { Pexp_extension $1 }
   | UNDERSCORE
       { Pexp_hole }
   | od=open_dot_declaration DOT mkrhs(LPAREN RPAREN {Lident "()"})
       { Pexp_open(od, mkexp ~loc:($loc($3)) (Pexp_construct($3, None))) }
-  | mod_longident DOT LPAREN seq_expr error
-      { unclosed "(" $loc($3) ")" $loc($5) }
   | LBRACE record_expr_content RBRACE
       { let (exten, fields) = $2 in
         Pexp_record(fields, exten) }
-  | LBRACE record_expr_content error
-      { unclosed "{" $loc($1) "}" $loc($3) }
   | od=open_dot_declaration DOT LBRACE record_expr_content RBRACE
       { let (exten, fields) = $4 in
         Pexp_open(od, mkexp ~loc:($startpos($3), $endpos)
                         (Pexp_record(fields, exten))) }
-  | mod_longident DOT LBRACE record_expr_content error
-      { unclosed "{" $loc($3) "}" $loc($5) }
   | array_exprs(LBRACKETBAR, BARRBRACKET)
       { Generic_array.expression
           "[|" "|]"
           (fun elts -> Pexp_array elts)
           $1 }
@@@@
                ~loc:(make_loc $sloc)
                (Iaexp_immutable_array elts)).pexp_desc)
           $1 }
   | LBRACKET expr_semi_list RBRACKET
       { Pexp_list $2 }
-  | LBRACKET expr_semi_list error
-      { unclosed "[" $loc($1) "]" $loc($3) }
   | comprehension_expr { $1 }
   | od=open_dot_declaration DOT comprehension_expr
       { Pexp_open(od, mkexp ~loc:($loc($3)) $3) }
   | od=open_dot_declaration DOT LBRACKET expr_semi_list RBRACKET
       { let list_exp = mkexp ~loc:($startpos($3), $endpos) (Pexp_list $4) in
         Pexp_open(od, list_exp) }
   | od=open_dot_declaration DOT mkrhs(LBRACKET RBRACKET {Lident "[]"})
       { Pexp_open(od, mkexp ~loc:$loc($3) (Pexp_construct($3, None))) }
-  | mod_longident DOT
-    LBRACKET expr_semi_list error
-      { unclosed "[" $loc($3) "]" $loc($5) }
   | od=open_dot_declaration DOT LPAREN MODULE ext_attributes module_expr COLON
     package_type RPAREN
       { let modexp =
           mkexp_attrs ~loc:($startpos($3), $endpos)
             (Pexp_pack ($6, Some $8)) $5 in
         Pexp_open(od, modexp) }
-  | mod_longident DOT
-    LPAREN MODULE ext_attributes module_expr COLON error
-      { unclosed "(" $loc($3) ")" $loc($8) }
 ;
 labeled_simple_expr:
     simple_expr %prec below_HASH
       { (Nolabel, $1) }
   | LABEL simple_expr %prec below_HASH
@@@@
             (ghpat ~loc:patloc
                (Ppat_constraint($2, ghtyp ~loc:($loc($4)) $4)))
         in
         let exp = mkexp_local_if $1 ~loc:$sloc $6 in
         (pat, exp) }
-  | let_ident COLON TYPE newtypes DOT core_type EQUAL seq_expr
+  | let_ident COLON TYPE lident_list DOT core_type EQUAL seq_expr
       { let exp, poly =
           wrap_type_annotation ~loc:$sloc $4 $6 $8 in
         let loc = ($startpos($1), $endpos($6)) in
         (ghpat ~loc (Ppat_constraint($1, poly)), exp) }
   | pattern_no_exn EQUAL seq_expr
@@@@
 ;
 let_binding_body:
   | let_binding_body_no_punning
       { let p,e = $1 in (p,e,false) }
 /* BEGIN AVOID */
-  | val_ident %prec below_HASH
-      { (mkpatvar ~loc:$loc $1, mkexpvar ~loc:$loc $1, true) }
   (* The production that allows puns is marked so that [make list-parse-errors]
      does not attempt to exploit it. That would be problematic because it
      would then generate bindings such as [let x], which are rejected by the
      auxiliary function [addlb] via a call to [syntax_error]. *)
 /* END AVOID */
@@@@
 strict_binding:
     EQUAL seq_expr
       { $2 }
   | labeled_simple_pattern fun_binding
       { let (l, o, p) = $1 in ghexp ~loc:$sloc (Pexp_fun(l, o, p, $2)) }
-  | LPAREN TYPE newtypes RPAREN fun_binding
+  | LPAREN TYPE lident_list RPAREN fun_binding
       { mk_newtypes ~loc:$sloc $3 $5 }
-  | LPAREN TYPE
-    newtype=mkrhs(name=LIDENT COLON layout=layout_annotation { Some name, Some layout })
-    RPAREN fun_binding
-      { mk_newtypes ~loc:$sloc [newtype] $5 }
 ;
 local_fun_binding:
     local_strict_binding
       { $1 }
   | type_constraint EQUAL seq_expr
@@@@
 local_strict_binding:
     EQUAL seq_expr
       { $2 }
   | labeled_simple_pattern local_fun_binding
       { let (l, o, p) = $1 in ghexp ~loc:$sloc (Pexp_fun(l, o, p, $2)) }
-  | LPAREN TYPE newtypes RPAREN local_fun_binding
+  | LPAREN TYPE lident_list RPAREN local_fun_binding
       { mk_newtypes ~loc:$sloc $3 $5 }
-  | LPAREN TYPE
-    newtype=mkrhs(name=LIDENT COLON layout=layout_annotation { Some name, Some layout })
-    RPAREN fun_binding
-      { mk_newtypes ~loc:$sloc [newtype] $5 }
 ;
 %inline match_cases:
   xs = preceded_or_separated_nonempty_llist(BAR, match_case)
     { xs }
 ;
@@@@
   | labeled_simple_pattern fun_def
       {
        let (l,o,p) = $1 in
        ghexp ~loc:$sloc (Pexp_fun(l, o, p, $2))
       }
-  | LPAREN TYPE newtypes RPAREN fun_def
+  | LPAREN TYPE lident_list RPAREN fun_def
       { mk_newtypes ~loc:$sloc $3 $5 }
-  | LPAREN TYPE
-    newtype=mkrhs(name=LIDENT COLON layout=layout_annotation { Some name, Some layout })
-    RPAREN fun_def
-      { mk_newtypes ~loc:$sloc [newtype] $5 }
 ;
 %inline expr_comma_list:
   es = separated_nontrivial_llist(COMMA, expr)
     { es }
 ;
@@@@
 ;
 type_constraint:
     COLON core_type                             { (Some $2, None) }
   | COLON core_type COLONGREATER core_type      { (Some $2, Some $4) }
   | COLONGREATER core_type                      { (None, Some $2) }
-  | COLON error                                 { syntax_error() }
-  | COLONGREATER error                          { syntax_error() }
 ;
 
-(* the thing between the [type] and the [.] in
-   [let : type <<here>>. 'a -> 'a = ...] *)
-newtypes: (* : (string with_loc * layout_annotation option) list *)
-  newtype+
-    { $1 }
-
-newtype: (* : string with_loc * layout_annotation option *)
-    mkrhs(LIDENT { Some $1, None }) { $1 }
-  | LPAREN
-    mkrhs(name=LIDENT COLON layout=layout_annotation {Some name, Some layout})
-    RPAREN
-      { $2 }
-
 /* Patterns */
 
 (* Whereas [pattern] is an arbitrary pattern, [pattern_no_exn] is a pattern
    that does not begin with the [EXCEPTION] keyword. Thus, [pattern_no_exn]
    is the intersection of the context-free language [pattern] with the
@@@@
 
    In order to avoid duplication between the definitions of [pattern] and
    [pattern_no_exn], we create a parameterized definition [pattern_(self)]
    and instantiate it twice. *)
 
-pattern:
+pattern [@recover.expr Annot.Pat.mk ()]:
     pattern_(pattern)
       { $1 }
   | EXCEPTION ext_attributes pattern %prec prec_constr_appl
       { mkpat_attrs ~loc:$sloc (Ppat_exception $3) $2}
 ;
@@@@
   | pattern_gen
       { $1 }
   | mkpat(
       self AS mkrhs(val_ident)
         { Ppat_alias($1, $3) }
-    | self AS error
-        { expecting $loc($3) "identifier" }
     | pattern_comma_list(self) %prec below_COMMA
         { Ppat_tuple(List.rev $1) }
-    | self COLONCOLON error
-        { expecting $loc($3) "pattern" }
     | self BAR pattern
         { let rec or_ p =
             match p with
             | {ppat_desc= Ppat_or (x :: t); ppat_attributes= []; _} -> or_ x @ t
             | _ -> [p]
           in
           Ppat_or (or_ $1 @ or_ $3) }
-    | self BAR error
-        { expecting $loc($3) "pattern" }
   ) { $1 }
 ;
 
 pattern_gen:
     simple_pattern
@@@@
       { Ppat_interval ($1, $3) }
   | mkrhs(constr_longident)
       { Ppat_construct($1, None) }
   | name_tag
       { Ppat_variant($1, None) }
-  | hash mkrhs(type_longident)
+  | HASH mkrhs(type_longident)
       { Ppat_type ($2) }
   | mkrhs(mod_longident) DOT simple_delimited_pattern
       { Ppat_open($1, $3) }
   | mkrhs(mod_longident) DOT mkrhs(LBRACKET RBRACKET {Lident "[]"})
     { Ppat_open($1, mkpat ~loc:$sloc (Ppat_construct($3, None))) }
   | mkrhs(mod_longident) DOT mkrhs(LPAREN RPAREN {Lident "()"})
     { Ppat_open($1, mkpat ~loc:$sloc (Ppat_construct($3, None))) }
   | mkrhs(mod_longident) DOT LPAREN pattern RPAREN
       { Ppat_open ($1, $4) }
-  | mod_longident DOT LPAREN pattern error
-      { unclosed "(" $loc($3) ")" $loc($5)  }
-  | mod_longident DOT LPAREN error
-      { expecting $loc($4) "pattern" }
-  | LPAREN pattern error
-      { unclosed "(" $loc($1) ")" $loc($3) }
   | LPAREN pattern COLON core_type RPAREN
       { Ppat_constraint($2, $4) }
-  | LPAREN pattern COLON core_type error
-      { unclosed "(" $loc($1) ")" $loc($5) }
-  | LPAREN pattern COLON error
-      { expecting $loc($4) "type" }
-  | LPAREN MODULE ext_attributes module_name COLON package_core_type
-    error
-      { unclosed "(" $loc($1) ")" $loc($7) }
   | extension
       { Ppat_extension $1 }
 ;
 
 simple_delimited_pattern:
   mkpat(
       LBRACE record_pat_content RBRACE
       { let (fields, closed) = $2 in
         Ppat_record(fields, closed) }
-    | LBRACE record_pat_content error
-      { unclosed "{" $loc($1) "}" $loc($3) }
     | LBRACKET pattern_semi_list RBRACKET
       { Ppat_list $2 }
-    | LBRACKET pattern_semi_list error
-      { unclosed "[" $loc($1) "]" $loc($3) }
     | array_patterns(LBRACKETBAR, BARRBRACKET)
         { Generic_array.pattern
             "[|" "|]"
             (fun elts -> Ppat_array elts)
             $1 }
@@@@
   ) { $1 }
 
 pattern_comma_list(self):
     pattern_comma_list(self) COMMA pattern      { $3 :: $1 }
   | self COMMA pattern                          { [$3; $1] }
-  | self COMMA error                            { expecting $loc($3) "pattern" }
 ;
 %inline pattern_semi_list:
   ps = separated_or_terminated_nonempty_list(SEMI, pattern)
     { ps }
 ;
@@@@
   ext = ext
   attrs1 = attributes
   flag = flag
   params = type_parameters
   id = mkrhs(LIDENT)
-  layout = layout_attr?
   kind_priv_manifest = kind
   cstrs = constraints
   attrs2 = post_item_attributes
     {
       let (kind, priv, manifest) = kind_priv_manifest in
       let docs = symbol_docs $sloc in
       let attrs = attrs1 @ attrs2 in
       let loc = make_loc $sloc in
       (flag, ext),
-      Type.mk id ~params ?layout ~cstrs ~kind ~priv ?manifest ~attrs ~loc ~docs
+      Type.mk id ~params ~cstrs ~kind ~priv ?manifest ~attrs ~loc ~docs
     }
 ;
 %inline generic_and_type_declaration(kind):
   AND
   attrs1 = attributes
   params = type_parameters
   id = mkrhs(LIDENT)
-  layout = layout_attr?
   kind_priv_manifest = kind
   cstrs = constraints
   attrs2 = post_item_attributes
     {
       let (kind, priv, manifest) = kind_priv_manifest in
       let docs = symbol_docs $sloc in
       let attrs = attrs1 @ attrs2 in
       let loc = make_loc $sloc in
       let text = symbol_text $symbolstartpos in
-      Type.mk id ~params ?layout ~cstrs ~kind ~priv ?manifest ~attrs ~loc ~docs ~text
+      Type.mk id ~params ~cstrs ~kind ~priv ?manifest ~attrs ~loc ~docs ~text
     }
 ;
 %inline constraints:
   llist(preceded(CONSTRAINT, constrain))
     { $1 }
@@@@
     ps = separated_nonempty_llist(COMMA, parenthesized_type_parameter)
     RPAREN
       { ps }
 ;
 
-layout_annotation: (* : layout_annotation *)
-  ident { let loc = make_loc $sloc in
-          mkloc (check_layout ~loc $1) loc }
-;
-
-layout_attr:
-  COLON
-  layout_annotation
-    { $2 }
-;
-
-%inline type_param_with_layout:
-  name=tyvar_name_or_underscore
-  attrs=attributes
-  COLON
-  layout=layout_annotation
-  { let descr = Ptyp_var (name, Some layout) in
-    mktyp ~loc:$sloc ~attrs descr }
+layout:
+  ident { check_layout $loc($1) $1 }
 ;
 
 parenthesized_type_parameter:
     type_parameter { $1 }
-  | type_variance type_param_with_layout
-    { $2, $1 }
+  | type_variance type_variable COLON layout
+      { {$2 with ptyp_attributes = [$4]}, $1 }
 ;
 
 type_parameter:
     type_variance type_variable attributes
       { {$2 with ptyp_attributes = $3}, $1 }
 ;
 
-%inline type_variable:
+type_variable:
   mktyp(
     QUOTE tyvar = ident
       { Ptyp_var (Some tyvar, None) }
   | UNDERSCORE
       { Ptyp_any }
   ) { $1 }
 ;
 
-%inline tyvar_name_or_underscore:
-    QUOTE ident
-      { Some $2 }
-  | UNDERSCORE
-      { None }
-;
-
 type_variance:
     /* empty */                             { [] }
   | PLUS                                    { [ mkvarinj "+" $sloc ] }
   | MINUS                                   { [ mkvarinj "-" $sloc ] }
   | BANG                                    { [ mkvarinj "!" $sloc ] }
   | PLUS BANG   { [ mkvarinj "+" $loc($1); mkvarinj "!" $loc($2) ] }
   | BANG PLUS   { [ mkvarinj "!" $loc($1); mkvarinj "+" $loc($2) ] }
   | MINUS BANG  { [ mkvarinj "-" $loc($1); mkvarinj "!" $loc($2) ] }
   | BANG MINUS  { [ mkvarinj "!" $loc($1); mkvarinj "-" $loc($2) ] }
-  | INFIXOP2
-      { if ($1 = "+!") || ($1 = "-!") then [ mkvarinj $1 $sloc ]
-        else expecting $loc($1) "type_variance" }
-  | PREFIXOP
-      { if ($1 = "!+") || ($1 = "!-") then [ mkvarinj $1 $sloc ]
-        else expecting $loc($1) "type_variance" }
 ;
 
 (* A sequence of constructor declarations is either a single BAR, which
    means that the list is empty, or a nonempty BAR-separated list of
    declarations, with an optional leading BAR. *)
@@@@
 ;
 %inline constructor_declaration(opening):
   d = generic_constructor_declaration(opening)
     {
       let cid, vars, args, res, attrs, loc, info = d in
-      Type.constructor
-        cid ~vars ~args ?res ~attrs ~loc ~info
+      Type.constructor cid ~vars ~args ?res ~attrs ~loc ~info
     }
 ;
 str_exception_declaration:
   sig_exception_declaration
     { $1 }
@@@@
   attrs1 = attributes
   id = mkrhs(constr_ident)
   vars_args_res = generalized_constructor_arguments
   attrs2 = attributes
   attrs = post_item_attributes
-    { let vars_layouts, args, res = vars_args_res in
+    { let vars, args, res = vars_args_res in
       let loc = make_loc ($startpos, $endpos(attrs2)) in
       let docs = symbol_docs $sloc in
-      let ext_ctor =
-        Te.constructor
-          ~loc ~attrs:(attrs1 @ attrs2) ~docs id
-          (Pext_decl (vars_layouts, args, res))
-      in
-      Te.mk_exception ~attrs ext_ctor, ext }
+      Te.mk_exception ~attrs
+        (Te.decl id ~vars ~args ?res ~attrs:(attrs1 @ attrs2) ~loc ~docs)
+      , ext }
 ;
 %inline let_exception_declaration:
     mkrhs(constr_ident) generalized_constructor_arguments attributes
-      { let vars_layouts, args, res = $2 in
-        Te.constructor
-            ~loc:(make_loc $sloc)
-            ~attrs:$3
-            $1
-            (Pext_decl (vars_layouts, args, res)) }
+      { let vars, args, res = $2 in
+        Te.decl $1 ~vars ~args ?res ~attrs:$3 ~loc:(make_loc $sloc) }
 ;
-
 generalized_constructor_arguments:
     /*empty*/                     { ([],Pcstr_tuple [],None) }
   | OF constructor_arguments      { ([],$2,None) }
   | COLON constructor_arguments MINUSGREATER atomic_type %prec below_HASH
                                   { ([],$2,Some $4) }
@@@@
       { $1 }
 ;
 %inline extension_constructor_declaration(opening):
   d = generic_constructor_declaration(opening)
     {
-      let name, vars_layouts, args, res, attrs, loc, info = d in
-      Te.constructor
-        ~loc ~attrs ~info name
-        (Pext_decl (vars_layouts, args, res))
+      let cid, vars, args, res, attrs, loc, info = d in
+      Te.decl cid ~vars ~args ?res ~attrs ~loc ~info
     }
 ;
 extension_constructor_rebind(opening):
   opening
   cid = mkrhs(constr_ident)
@@@@
   | EQUAL PRIVATE  { Private (make_loc $loc($2)) }
 ;
 
 /* Polymorphic types */
 
-%inline typevar: (* : string with_loc * layout_annotation option *)
-    QUOTE mkrhs(ident {(Some $1, None)})
-      { $2 }
-    | LPAREN QUOTE mkrhs(
-        ident COLON layout=layout_annotation
-        { (Some $1, Some layout) }
-    ) RPAREN
-      { $3 }
+%inline typevar:
+  QUOTE mkrhs(ident {Some $1, None})
+    { $2 }
 ;
 %inline typevar_list:
-  (* : (string with_loc * layout_annotation option) list *)
   nonempty_llist(typevar)
     { $1 }
 ;
 %inline poly(X):
   typevar_list DOT X
-    { Ptyp_poly ($1, $3) }
+    { Ptyp_poly($1, $3) }
 ;
 possibly_poly(X):
   X
     { $1 }
 | mktyp(poly(X))
@@@@
     function_type
       { $1 }
   | mktyp(
       ty = alias_type AS QUOTE tyvar = mkrhs(ident {Some $1, None})
         { Ptyp_alias(ty, tyvar) }
-    | aliased_type = alias_type AS
-      LPAREN
-      tyvar=mkrhs(
-        name = tyvar_name_or_underscore
-        COLON
-        layout = layout_annotation
-        {name, Some layout}
-      )
-      RPAREN
-        { Ptyp_alias (aliased_type, tyvar) }
     )
     { $1 }
 ;
 
 (* Function types include:
@@@@
                                           ?foo: int -> int
  *)
 function_type:
   | ty = tuple_type
     %prec MINUSGREATER
-      { ty }
+     { ty }
   | ty = strict_function_type
-      { ty }
+     { ty }
 ;
 strict_function_type:
   | mktyp(
       label = arg_label
       local = optional_local
@@@@
       { $1 }
 ;
 %inline param_type:
   | mktyp(
     LPAREN vars = typevar_list DOT ty = core_type RPAREN
-      { Ptyp_poly (vars, ty) }
+      { Ptyp_poly(vars, ty) }
     )
     { $1 }
   | ty = tuple_type
     { ty }
 ;
@@@@
         { Ptyp_var (Some $2, None) }
     | UNDERSCORE
         { Ptyp_any }
     | tys = actual_type_parameters
       tid = mkrhs(type_longident)
-      HASH_SUFFIX
-        { Jane.ptyp_constr_unboxed tid tys }
-    | tys = actual_type_parameters
-      tid = mkrhs(type_longident)
-        { Ptyp_constr(tid, tys) } %prec below_HASH
+        { Ptyp_constr(tid, tys) }
     | LESS meth_list GREATER
         { let (f, c) = $2 in Ptyp_object (f, c) }
     | LESS GREATER
         { Ptyp_object ([], OClosed) }
     | tys = actual_type_parameters
@@@@
         { Ptyp_variant($3, Closed, Some []) }
     | LBRACKETLESS BAR? row_field_list GREATER name_tag_list RBRACKET
         { Ptyp_variant($3, Closed, Some $5) }
     | extension
         { Ptyp_extension $1 }
-    | LPAREN QUOTE name=ident COLON layout=layout_annotation RPAREN
-      { Ptyp_var (Some name, Some layout) }
-  | LPAREN UNDERSCORE COLON layout=layout_annotation RPAREN
-      { Ptyp_var (None, Some layout) }
-
   )
   { $1 } /* end mktyp group */
 ;
 
 (* This is the syntax of the actual type parameters in an application of
@@@@
   | CHAR         { mkconst ~loc:$sloc (Pconst_char $1) }
   | STRING       { let (s, strloc, d) = $1 in
                    mkconst ~loc:$sloc (Pconst_string (s,strloc,d)) }
   | FLOAT        { let (f, m) = $1 in
                    mkconst ~loc:$sloc (Pconst_float (f, m)) }
-
-  (* Jane Street extension *)
-  | HASH_INT     { let (n, m) = $1 in
-                   mkconst ~loc:$sloc (Jane.pconst_unboxed_integer Positive n m) }
-  | HASH_FLOAT   { let (f, m) = $1 in
-                   mkconst ~loc:$sloc (Jane.pconst_unboxed_float Positive f m) }
-  (* End Jane Street extension *)
 ;
 signed_constant:
     constant     { $1 }
   | MINUS INT    { let (n, m) = $2 in
                    mkconst ~loc:$sloc (Pconst_integer("-" ^ n, m)) }
@@@@
                    mkconst ~loc:$sloc (Pconst_float("-" ^ f, m)) }
   | PLUS INT     { let (n, m) = $2 in
                    mkconst ~loc:$sloc (Pconst_integer (n, m)) }
   | PLUS FLOAT   { let (f, m) = $2 in
                    mkconst ~loc:$sloc (Pconst_float(f, m)) }
-
-  (* Jane Street extension *)
-  | MINUS HASH_INT    { let (n, m) = $2 in
-                        mkconst ~loc:$sloc
-                          (Jane.pconst_unboxed_integer Negative n m) }
-  | MINUS HASH_FLOAT  { let (f, m) = $2 in
-                        mkconst ~loc:$sloc
-                          (Jane.pconst_unboxed_float Negative f m) }
-  | PLUS HASH_INT     { let (n, m) = $2 in
-                        mkconst ~loc:$sloc
-                          (Jane.pconst_unboxed_integer Positive n m) }
-  | PLUS HASH_FLOAT   { let (f, m) = $2 in
-                        mkconst ~loc:$sloc
-                          (Jane.pconst_unboxed_float Positive f m) }
-  (* End Jane Street extension *)
 ;
 
 /* Identifiers and long identifiers */
 
 ident:
     UIDENT                    { $1 }
   | LIDENT                    { $1 }
 ;
 val_extra_ident:
   | LPAREN operator RPAREN    { $2 }
-  | LPAREN operator error     { unclosed "(" $loc($1) ")" $loc($3) }
-  | LPAREN error              { expecting $loc($2) "operator" }
-  | LPAREN MODULE error       { expecting $loc($3) "module-expr" }
 ;
 val_ident:
     LIDENT                    { $1 }
   | val_extra_ident           { $1 }
 ;
@@@@
 ;
 mod_ext_longident:
     mod_ext_longident_ { $1 }
   | mod_ext_longident LPAREN mod_ext_longident RPAREN
       { lapply ~loc:$sloc $1 $3 }
-  | mod_ext_longident LPAREN error
-      { expecting $loc($3) "module path" }
 ;
 mty_longident:
     mk_longident(mod_ext_longident,ident) { $1 }
 ;
 clty_longident:
@@@@
 /* END AVOID */
 
 /* Toplevel directives */
 
 toplevel_directive:
-  hash dir = mkrhs(ident)
+  HASH dir = mkrhs(ident)
   arg = ioption(mk_directive_arg(toplevel_directive_argument))
     { mk_directive ~loc:$sloc dir arg }
 ;
 
 %inline toplevel_directive_argument:
@@@@
   | NONREC                                      { Nonrecursive }
 ;
 %inline no_nonrec_flag:
     /* empty */ { Recursive }
 /* BEGIN AVOID */
-  | NONREC      { not_expecting $loc "nonrec flag" }
 /* END AVOID */
 ;
 direction_flag:
     TO                                          { Upto }
   | DOWNTO                                      { Downto }
@@@@
   | PERCENT attr_id { Some $2 }
 ;
 %inline no_ext:
   | /* empty */     { None }
 /* BEGIN AVOID */
-  | PERCENT attr_id { not_expecting $loc "extension" }
 /* END AVOID */
 ;
 %inline ext_attributes:
   ext attributes    { $1, $2 }
 ;
